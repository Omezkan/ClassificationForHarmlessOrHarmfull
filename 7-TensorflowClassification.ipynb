{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>TCP_CONVERSATION_EXCHANGE</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>...</th>\n",
       "      <th>SOURCE_I</th>\n",
       "      <th>SOURCE_J</th>\n",
       "      <th>SOURCE_K</th>\n",
       "      <th>SOURCE_M</th>\n",
       "      <th>SOURCE_L</th>\n",
       "      <th>SOURCE_N</th>\n",
       "      <th>SOURCE_O</th>\n",
       "      <th>SOURCE_P</th>\n",
       "      <th>SOURCE_R</th>\n",
       "      <th>SOURCE_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23.303047</td>\n",
       "      <td>13.445560</td>\n",
       "      <td>159.066933</td>\n",
       "      <td>1296.628667</td>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.359585</td>\n",
       "      <td>0.388730</td>\n",
       "      <td>0.190544</td>\n",
       "      <td>0.313341</td>\n",
       "      <td>...</td>\n",
       "      <td>32.875560</td>\n",
       "      <td>22.448127</td>\n",
       "      <td>239.118533</td>\n",
       "      <td>2615.278000</td>\n",
       "      <td>0.210103</td>\n",
       "      <td>0.862174</td>\n",
       "      <td>0.922148</td>\n",
       "      <td>0.343781</td>\n",
       "      <td>0.595983</td>\n",
       "      <td>0.154015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.645007</td>\n",
       "      <td>23.018073</td>\n",
       "      <td>172.149800</td>\n",
       "      <td>1717.612000</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.101865</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.090894</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>...</td>\n",
       "      <td>32.370380</td>\n",
       "      <td>30.323753</td>\n",
       "      <td>205.698933</td>\n",
       "      <td>2533.672000</td>\n",
       "      <td>0.160362</td>\n",
       "      <td>0.241709</td>\n",
       "      <td>0.312953</td>\n",
       "      <td>240.932000</td>\n",
       "      <td>356.216667</td>\n",
       "      <td>0.115311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25.505113</td>\n",
       "      <td>27.525833</td>\n",
       "      <td>168.393333</td>\n",
       "      <td>1558.286000</td>\n",
       "      <td>0.141969</td>\n",
       "      <td>0.207124</td>\n",
       "      <td>0.255699</td>\n",
       "      <td>0.165673</td>\n",
       "      <td>0.268004</td>\n",
       "      <td>...</td>\n",
       "      <td>30.531007</td>\n",
       "      <td>33.069860</td>\n",
       "      <td>197.538333</td>\n",
       "      <td>2213.724667</td>\n",
       "      <td>0.187046</td>\n",
       "      <td>0.549869</td>\n",
       "      <td>0.583418</td>\n",
       "      <td>314.766000</td>\n",
       "      <td>0.468004</td>\n",
       "      <td>0.113445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.792707</td>\n",
       "      <td>26.398893</td>\n",
       "      <td>100.491960</td>\n",
       "      <td>500.128200</td>\n",
       "      <td>0.184585</td>\n",
       "      <td>0.367745</td>\n",
       "      <td>0.312693</td>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.336398</td>\n",
       "      <td>...</td>\n",
       "      <td>19.313420</td>\n",
       "      <td>34.326333</td>\n",
       "      <td>128.069607</td>\n",
       "      <td>735.360733</td>\n",
       "      <td>0.271761</td>\n",
       "      <td>1.122147</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.333548</td>\n",
       "      <td>0.859842</td>\n",
       "      <td>224.092667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>26.282313</td>\n",
       "      <td>18.575080</td>\n",
       "      <td>174.999533</td>\n",
       "      <td>1680.047333</td>\n",
       "      <td>0.129922</td>\n",
       "      <td>0.172020</td>\n",
       "      <td>256.476000</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.234326</td>\n",
       "      <td>...</td>\n",
       "      <td>29.196813</td>\n",
       "      <td>21.593207</td>\n",
       "      <td>197.149733</td>\n",
       "      <td>2040.150000</td>\n",
       "      <td>0.177979</td>\n",
       "      <td>265.543333</td>\n",
       "      <td>0.518133</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.306217</td>\n",
       "      <td>0.099456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1</td>\n",
       "      <td>27.927387</td>\n",
       "      <td>29.002513</td>\n",
       "      <td>183.937333</td>\n",
       "      <td>1915.798000</td>\n",
       "      <td>143.782000</td>\n",
       "      <td>0.150129</td>\n",
       "      <td>0.315932</td>\n",
       "      <td>0.179922</td>\n",
       "      <td>0.223575</td>\n",
       "      <td>...</td>\n",
       "      <td>32.966233</td>\n",
       "      <td>34.196800</td>\n",
       "      <td>215.154867</td>\n",
       "      <td>2625.640667</td>\n",
       "      <td>182.642000</td>\n",
       "      <td>0.273704</td>\n",
       "      <td>0.531993</td>\n",
       "      <td>0.287046</td>\n",
       "      <td>266.838667</td>\n",
       "      <td>0.092163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>26.075060</td>\n",
       "      <td>36.593167</td>\n",
       "      <td>169.947733</td>\n",
       "      <td>1633.415333</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.133937</td>\n",
       "      <td>186.528000</td>\n",
       "      <td>0.126826</td>\n",
       "      <td>0.226942</td>\n",
       "      <td>...</td>\n",
       "      <td>30.686447</td>\n",
       "      <td>49.546500</td>\n",
       "      <td>200.776667</td>\n",
       "      <td>2242.222000</td>\n",
       "      <td>0.151036</td>\n",
       "      <td>0.248963</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>0.210880</td>\n",
       "      <td>0.333160</td>\n",
       "      <td>0.085971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>21.502533</td>\n",
       "      <td>36.372960</td>\n",
       "      <td>140.284600</td>\n",
       "      <td>1111.525533</td>\n",
       "      <td>0.109520</td>\n",
       "      <td>0.132513</td>\n",
       "      <td>0.119831</td>\n",
       "      <td>0.068679</td>\n",
       "      <td>205.958000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.585427</td>\n",
       "      <td>44.196773</td>\n",
       "      <td>164.118733</td>\n",
       "      <td>1455.954667</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.400776</td>\n",
       "      <td>0.440802</td>\n",
       "      <td>0.183678</td>\n",
       "      <td>0.287305</td>\n",
       "      <td>0.101295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>26.683867</td>\n",
       "      <td>37.992127</td>\n",
       "      <td>181.476200</td>\n",
       "      <td>1638.596667</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>358.807333</td>\n",
       "      <td>0.455180</td>\n",
       "      <td>196.890667</td>\n",
       "      <td>0.310491</td>\n",
       "      <td>...</td>\n",
       "      <td>33.341880</td>\n",
       "      <td>51.062040</td>\n",
       "      <td>239.118533</td>\n",
       "      <td>2358.802000</td>\n",
       "      <td>213.730000</td>\n",
       "      <td>1.124479</td>\n",
       "      <td>1.215929</td>\n",
       "      <td>343.263333</td>\n",
       "      <td>0.529403</td>\n",
       "      <td>160.621333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0</td>\n",
       "      <td>10.051787</td>\n",
       "      <td>31.787480</td>\n",
       "      <td>62.072373</td>\n",
       "      <td>234.455333</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205569</td>\n",
       "      <td>...</td>\n",
       "      <td>12248.672000</td>\n",
       "      <td>39.339273</td>\n",
       "      <td>76.631920</td>\n",
       "      <td>347.926533</td>\n",
       "      <td>0.116528</td>\n",
       "      <td>0.083471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371890</td>\n",
       "      <td>0.091179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS  TCP_CONVERSATION_EXCHANGE  \\\n",
       "0       1   23.303047                  13.445560                 159.066933   \n",
       "1       1   26.645007                  23.018073                 172.149800   \n",
       "2       1   25.505113                  27.525833                 168.393333   \n",
       "3       1   14.792707                  26.398893                 100.491960   \n",
       "4       1   26.282313                  18.575080                 174.999533   \n",
       "..    ...         ...                        ...                        ...   \n",
       "543     1   27.927387                  29.002513                 183.937333   \n",
       "544     1   26.075060                  36.593167                 169.947733   \n",
       "545     1   21.502533                  36.372960                 140.284600   \n",
       "546     1   26.683867                  37.992127                 181.476200   \n",
       "547     0   10.051787                  31.787480                  62.072373   \n",
       "\n",
       "     DIST_REMOTE_TCP_PORT  REMOTE_IPS   APP_BYTES  SOURCE_APP_PACKETS  \\\n",
       "0             1296.628667    0.153367    0.359585            0.388730   \n",
       "1             1717.612000    0.109767    0.101865            0.112564   \n",
       "2             1558.286000    0.141969    0.207124            0.255699   \n",
       "3              500.128200    0.184585    0.367745            0.312693   \n",
       "4             1680.047333    0.129922    0.172020          256.476000   \n",
       "..                    ...         ...         ...                 ...   \n",
       "543           1915.798000  143.782000    0.150129            0.315932   \n",
       "544           1633.415333    0.126684    0.133937          186.528000   \n",
       "545           1111.525533    0.109520    0.132513            0.119831   \n",
       "546           1638.596667    0.152590  358.807333            0.455180   \n",
       "547            234.455333    0.068173    0.056502            0.000000   \n",
       "\n",
       "     REMOTE_APP_PACKETS  SOURCE_APP_BYTES  ...      SOURCE_I   SOURCE_J  \\\n",
       "0              0.190544          0.313341  ...     32.875560  22.448127   \n",
       "1              0.090894          0.234714  ...     32.370380  30.323753   \n",
       "2              0.165673          0.268004  ...     30.531007  33.069860   \n",
       "3              0.136269          0.336398  ...     19.313420  34.326333   \n",
       "4              0.135103          0.234326  ...     29.196813  21.593207   \n",
       "..                  ...               ...  ...           ...        ...   \n",
       "543            0.179922          0.223575  ...     32.966233  34.196800   \n",
       "544            0.126826          0.226942  ...     30.686447  49.546500   \n",
       "545            0.068679        205.958000  ...     24.585427  44.196773   \n",
       "546          196.890667          0.310491  ...     33.341880  51.062040   \n",
       "547            0.000000          0.205569  ...  12248.672000  39.339273   \n",
       "\n",
       "       SOURCE_K     SOURCE_M    SOURCE_L    SOURCE_N  SOURCE_O    SOURCE_P  \\\n",
       "0    239.118533  2615.278000    0.210103    0.862174  0.922148    0.343781   \n",
       "1    205.698933  2533.672000    0.160362    0.241709  0.312953  240.932000   \n",
       "2    197.538333  2213.724667    0.187046    0.549869  0.583418  314.766000   \n",
       "3    128.069607   735.360733    0.271761    1.122147  0.889764    0.333548   \n",
       "4    197.149733  2040.150000    0.177979  265.543333  0.518133    0.210492   \n",
       "..          ...          ...         ...         ...       ...         ...   \n",
       "543  215.154867  2625.640667  182.642000    0.273704  0.531993    0.287046   \n",
       "544  200.776667  2242.222000    0.151036    0.248963  0.416450    0.210880   \n",
       "545  164.118733  1455.954667    0.147538    0.400776  0.440802    0.183678   \n",
       "546  239.118533  2358.802000  213.730000    1.124479  1.215929  343.263333   \n",
       "547   76.631920   347.926533    0.116528    0.083471  0.000000    0.000000   \n",
       "\n",
       "       SOURCE_R    SOURCE_S  \n",
       "0      0.595983    0.154015  \n",
       "1    356.216667    0.115311  \n",
       "2      0.468004    0.113445  \n",
       "3      0.859842  224.092667  \n",
       "4      0.306217    0.099456  \n",
       "..          ...         ...  \n",
       "543  266.838667    0.092163  \n",
       "544    0.333160    0.085971  \n",
       "545    0.287305    0.101295  \n",
       "546    0.529403  160.621333  \n",
       "547    0.371890    0.091179  \n",
       "\n",
       "[548 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = pd.read_excel(\"C:\\\\Users\\\\Computer\\\\Desktop\\\\Software\\\\AI\\\\NumpyPandasMatplotlib\\\\WholeDataScienceFiles\\\\maliciousornot.xlsx\")\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 548 entries, 0 to 547\n",
      "Data columns (total 31 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Type                       548 non-null    int64  \n",
      " 1   URL_LENGTH                 548 non-null    float64\n",
      " 2   NUMBER_SPECIAL_CHARACTERS  548 non-null    float64\n",
      " 3   TCP_CONVERSATION_EXCHANGE  548 non-null    float64\n",
      " 4   DIST_REMOTE_TCP_PORT       548 non-null    float64\n",
      " 5   REMOTE_IPS                 548 non-null    float64\n",
      " 6   APP_BYTES                  548 non-null    float64\n",
      " 7   SOURCE_APP_PACKETS         548 non-null    float64\n",
      " 8   REMOTE_APP_PACKETS         548 non-null    float64\n",
      " 9   SOURCE_APP_BYTES           548 non-null    float64\n",
      " 10  REMOTE_APP_BYTES           548 non-null    float64\n",
      " 11  APP_PACKETS                548 non-null    float64\n",
      " 12  DNS_QUERY_TIMES            548 non-null    float64\n",
      " 13  SOURCE_A                   548 non-null    float64\n",
      " 14  SOURCE_B                   548 non-null    float64\n",
      " 15  SOURCE_C                   548 non-null    float64\n",
      " 16  SOURCE_D                   548 non-null    float64\n",
      " 17  SOURCE_F                   548 non-null    float64\n",
      " 18  SOURCE_E                   548 non-null    float64\n",
      " 19  SOURCE_G                   548 non-null    float64\n",
      " 20  SOURCE_H                   548 non-null    float64\n",
      " 21  SOURCE_I                   548 non-null    float64\n",
      " 22  SOURCE_J                   548 non-null    float64\n",
      " 23  SOURCE_K                   548 non-null    float64\n",
      " 24  SOURCE_M                   548 non-null    float64\n",
      " 25  SOURCE_L                   548 non-null    float64\n",
      " 26  SOURCE_N                   548 non-null    float64\n",
      " 27  SOURCE_O                   548 non-null    float64\n",
      " 28  SOURCE_P                   548 non-null    float64\n",
      " 29  SOURCE_R                   548 non-null    float64\n",
      " 30  SOURCE_S                   548 non-null    float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 132.8 KB\n"
     ]
    }
   ],
   "source": [
    "dataFrame.info()\n",
    "# verimiz hakkında bilgi verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>TCP_CONVERSATION_EXCHANGE</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>...</th>\n",
       "      <th>SOURCE_I</th>\n",
       "      <th>SOURCE_J</th>\n",
       "      <th>SOURCE_K</th>\n",
       "      <th>SOURCE_M</th>\n",
       "      <th>SOURCE_L</th>\n",
       "      <th>SOURCE_N</th>\n",
       "      <th>SOURCE_O</th>\n",
       "      <th>SOURCE_P</th>\n",
       "      <th>SOURCE_R</th>\n",
       "      <th>SOURCE_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383212</td>\n",
       "      <td>949.973475</td>\n",
       "      <td>25.015747</td>\n",
       "      <td>119.725438</td>\n",
       "      <td>857.123249</td>\n",
       "      <td>5.785481</td>\n",
       "      <td>6.499737</td>\n",
       "      <td>10.069604</td>\n",
       "      <td>3.181365</td>\n",
       "      <td>22.809689</td>\n",
       "      <td>...</td>\n",
       "      <td>399.714125</td>\n",
       "      <td>33.295952</td>\n",
       "      <td>139.830855</td>\n",
       "      <td>1155.666380</td>\n",
       "      <td>14.295530</td>\n",
       "      <td>32.855845</td>\n",
       "      <td>34.913670</td>\n",
       "      <td>11.758580</td>\n",
       "      <td>40.829159</td>\n",
       "      <td>2.637820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486613</td>\n",
       "      <td>3202.802599</td>\n",
       "      <td>5.605685</td>\n",
       "      <td>31.842845</td>\n",
       "      <td>461.579998</td>\n",
       "      <td>27.796268</td>\n",
       "      <td>35.390031</td>\n",
       "      <td>46.976527</td>\n",
       "      <td>21.315640</td>\n",
       "      <td>70.942060</td>\n",
       "      <td>...</td>\n",
       "      <td>2117.405314</td>\n",
       "      <td>7.956699</td>\n",
       "      <td>44.017609</td>\n",
       "      <td>746.777340</td>\n",
       "      <td>49.075477</td>\n",
       "      <td>126.026487</td>\n",
       "      <td>149.880701</td>\n",
       "      <td>52.045464</td>\n",
       "      <td>119.531119</td>\n",
       "      <td>19.086225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.051787</td>\n",
       "      <td>12.577687</td>\n",
       "      <td>56.722647</td>\n",
       "      <td>185.880333</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.025104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151165</td>\n",
       "      <td>...</td>\n",
       "      <td>10.271993</td>\n",
       "      <td>15.569907</td>\n",
       "      <td>65.297753</td>\n",
       "      <td>239.895733</td>\n",
       "      <td>0.105246</td>\n",
       "      <td>0.044456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202720</td>\n",
       "      <td>0.071295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.838688</td>\n",
       "      <td>20.987638</td>\n",
       "      <td>97.470595</td>\n",
       "      <td>544.622900</td>\n",
       "      <td>0.112309</td>\n",
       "      <td>0.084718</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.211755</td>\n",
       "      <td>...</td>\n",
       "      <td>17.082208</td>\n",
       "      <td>27.325057</td>\n",
       "      <td>108.999062</td>\n",
       "      <td>667.971017</td>\n",
       "      <td>0.154501</td>\n",
       "      <td>0.196275</td>\n",
       "      <td>0.152558</td>\n",
       "      <td>0.084805</td>\n",
       "      <td>0.331022</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.069900</td>\n",
       "      <td>24.423510</td>\n",
       "      <td>112.920683</td>\n",
       "      <td>723.637967</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>0.122720</td>\n",
       "      <td>0.085395</td>\n",
       "      <td>0.045304</td>\n",
       "      <td>0.235168</td>\n",
       "      <td>...</td>\n",
       "      <td>19.838030</td>\n",
       "      <td>32.972710</td>\n",
       "      <td>127.117537</td>\n",
       "      <td>901.616767</td>\n",
       "      <td>0.173899</td>\n",
       "      <td>0.297149</td>\n",
       "      <td>0.328950</td>\n",
       "      <td>0.132318</td>\n",
       "      <td>0.374869</td>\n",
       "      <td>0.103743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.264187</td>\n",
       "      <td>28.270650</td>\n",
       "      <td>137.175800</td>\n",
       "      <td>1037.270550</td>\n",
       "      <td>0.137694</td>\n",
       "      <td>0.172215</td>\n",
       "      <td>0.189799</td>\n",
       "      <td>0.101201</td>\n",
       "      <td>0.266159</td>\n",
       "      <td>...</td>\n",
       "      <td>25.919620</td>\n",
       "      <td>38.698083</td>\n",
       "      <td>164.636867</td>\n",
       "      <td>1460.488333</td>\n",
       "      <td>0.194689</td>\n",
       "      <td>0.497797</td>\n",
       "      <td>0.559098</td>\n",
       "      <td>0.223866</td>\n",
       "      <td>0.430342</td>\n",
       "      <td>0.119375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12828.981333</td>\n",
       "      <td>50.880693</td>\n",
       "      <td>244.170333</td>\n",
       "      <td>3239.628667</td>\n",
       "      <td>159.326000</td>\n",
       "      <td>358.807333</td>\n",
       "      <td>405.439333</td>\n",
       "      <td>209.844000</td>\n",
       "      <td>393.781333</td>\n",
       "      <td>...</td>\n",
       "      <td>12928.722000</td>\n",
       "      <td>64.170813</td>\n",
       "      <td>325.387733</td>\n",
       "      <td>5510.348000</td>\n",
       "      <td>239.636667</td>\n",
       "      <td>1370.462667</td>\n",
       "      <td>1621.757333</td>\n",
       "      <td>376.942000</td>\n",
       "      <td>704.661333</td>\n",
       "      <td>224.092667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Type    URL_LENGTH  NUMBER_SPECIAL_CHARACTERS  \\\n",
       "count  548.000000    548.000000                 548.000000   \n",
       "mean     0.383212    949.973475                  25.015747   \n",
       "std      0.486613   3202.802599                   5.605685   \n",
       "min      0.000000     10.051787                  12.577687   \n",
       "25%      0.000000     15.838688                  20.987638   \n",
       "50%      0.000000     18.069900                  24.423510   \n",
       "75%      1.000000     23.264187                  28.270650   \n",
       "max      1.000000  12828.981333                  50.880693   \n",
       "\n",
       "       TCP_CONVERSATION_EXCHANGE  DIST_REMOTE_TCP_PORT  REMOTE_IPS  \\\n",
       "count                 548.000000            548.000000  548.000000   \n",
       "mean                  119.725438            857.123249    5.785481   \n",
       "std                    31.842845            461.579998   27.796268   \n",
       "min                    56.722647            185.880333    0.068173   \n",
       "25%                    97.470595            544.622900    0.112309   \n",
       "50%                   112.920683            723.637967    0.125084   \n",
       "75%                   137.175800           1037.270550    0.137694   \n",
       "max                   244.170333           3239.628667  159.326000   \n",
       "\n",
       "        APP_BYTES  SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  SOURCE_APP_BYTES  \\\n",
       "count  548.000000          548.000000          548.000000        548.000000   \n",
       "mean     6.499737           10.069604            3.181365         22.809689   \n",
       "std     35.390031           46.976527           21.315640         70.942060   \n",
       "min      0.025104            0.000000            0.000000          0.151165   \n",
       "25%      0.084718            0.038394            0.026383          0.211755   \n",
       "50%      0.122720            0.085395            0.045304          0.235168   \n",
       "75%      0.172215            0.189799            0.101201          0.266159   \n",
       "max    358.807333          405.439333          209.844000        393.781333   \n",
       "\n",
       "       ...      SOURCE_I    SOURCE_J    SOURCE_K     SOURCE_M    SOURCE_L  \\\n",
       "count  ...    548.000000  548.000000  548.000000   548.000000  548.000000   \n",
       "mean   ...    399.714125   33.295952  139.830855  1155.666380   14.295530   \n",
       "std    ...   2117.405314    7.956699   44.017609   746.777340   49.075477   \n",
       "min    ...     10.271993   15.569907   65.297753   239.895733    0.105246   \n",
       "25%    ...     17.082208   27.325057  108.999062   667.971017    0.154501   \n",
       "50%    ...     19.838030   32.972710  127.117537   901.616767    0.173899   \n",
       "75%    ...     25.919620   38.698083  164.636867  1460.488333    0.194689   \n",
       "max    ...  12928.722000   64.170813  325.387733  5510.348000  239.636667   \n",
       "\n",
       "          SOURCE_N     SOURCE_O    SOURCE_P    SOURCE_R    SOURCE_S  \n",
       "count   548.000000   548.000000  548.000000  548.000000  548.000000  \n",
       "mean     32.855845    34.913670   11.758580   40.829159    2.637820  \n",
       "std     126.026487   149.880701   52.045464  119.531119   19.086225  \n",
       "min       0.044456     0.000000    0.000000    0.202720    0.071295  \n",
       "25%       0.196275     0.152558    0.084805    0.331022    0.093099  \n",
       "50%       0.297149     0.328950    0.132318    0.374869    0.103743  \n",
       "75%       0.497797     0.559098    0.223866    0.430342    0.119375  \n",
       "max    1370.462667  1621.757333  376.942000  704.661333  224.092667  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.sort_values of Type                         1.000000\n",
       "URL_LENGTH                  -0.228422\n",
       "NUMBER_SPECIAL_CHARACTERS    0.412095\n",
       "TCP_CONVERSATION_EXCHANGE    0.744570\n",
       "DIST_REMOTE_TCP_PORT         0.710294\n",
       "REMOTE_IPS                   0.126232\n",
       "APP_BYTES                    0.096659\n",
       "SOURCE_APP_PACKETS           0.129433\n",
       "REMOTE_APP_PACKETS           0.139874\n",
       "SOURCE_APP_BYTES            -0.086080\n",
       "REMOTE_APP_BYTES            -0.048806\n",
       "APP_PACKETS                  0.240818\n",
       "DNS_QUERY_TIMES             -0.011055\n",
       "SOURCE_A                     0.536539\n",
       "SOURCE_B                    -0.128587\n",
       "SOURCE_C                    -0.075369\n",
       "SOURCE_D                     0.029479\n",
       "SOURCE_F                    -0.007551\n",
       "SOURCE_E                     0.001985\n",
       "SOURCE_G                    -0.017433\n",
       "SOURCE_H                     0.055045\n",
       "SOURCE_I                    -0.138708\n",
       "SOURCE_J                     0.453197\n",
       "SOURCE_K                     0.784173\n",
       "SOURCE_M                     0.734002\n",
       "SOURCE_L                     0.022932\n",
       "SOURCE_N                     0.088076\n",
       "SOURCE_O                     0.063622\n",
       "SOURCE_P                     0.205141\n",
       "SOURCE_R                     0.069140\n",
       "SOURCE_S                     0.141134\n",
       "Name: Type, dtype: float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.corr()[\"Type\"].sort_values\n",
    "# verimizideki kolonların type üzerindeki etkisini görüyoruz hangisi olumlu hangisi olumsuz etkiliyor onu görüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Type', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbn.countplot(x=\"Type\", data=dataFrame)\n",
    "# bir sınıflandırma problemindeki veri kümesinde sınıflar çok dengeli dağılmamışsa yani bir sınıftan çok fazla varken diğer\n",
    "# sınıftan çok az varsa o veri kümesi düzgün bir veri kümesi değildir ve doğru eğitim yapılamayabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataFrame.corr()[\"Type\"].sort_values().plot(kind=\"bar\")\n",
    "# burda diğer kolonların type kolonlarına etkisini bar grafiğinde göster dedik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL OLUŞTURMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataFrame[\"Type\"].values\n",
    "x = dataFrame.drop(\"Type\",axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# earlystopping ve dropout sınıfını overfitting durumunda nasıl düzeltme yapacağımızı görmek için import ettik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30, activation=\"relu\"))\n",
    "# bunu 30 nöron vermemizin sebebi bizim 30 tane kolonumuz varmış ve giriş katmanını kaç kolon varsa o kadar nöronla başlatmak\n",
    "# önerilir\n",
    "\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "# bunlar ara yani gizli katmanlar bunların nöron sayısını 15 seçmemizin sebebi ise\n",
    "# şuan giriş katmanını 30 nöron seçtik ara katmanlarında nöron sayısını 30 ile 1 arasında bir sayı seçmek\n",
    "# mantıklı olur.\n",
    "\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "# bu da çıkış yani output katmanı. Bu sefer buna da activation fonksiyonu verdik bu fonksiyon 0 ile 1 arasında bir değer döndürür\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\")\n",
    "# binary_crossentropy loss fonksiyonu sınıflandırma problemlerinde kullanılan bir fonksiyon\n",
    "\n",
    "# yukarıda katmanlardaki nöron sayılarını belirlemek için genel geçer bir kural gördük o kural ile başlayıp\n",
    "# duruma göre nöron sayısı katman sayısı felan değiştirebilirsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 1s 20ms/step - loss: 0.6938 - val_loss: 0.6875\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6686 - val_loss: 0.6827\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6474 - val_loss: 0.6748\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.6612\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6060 - val_loss: 0.6526\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5906 - val_loss: 0.6248\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5387 - val_loss: 0.6014\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5294 - val_loss: 0.5671\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4664 - val_loss: 0.5315\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4400 - val_loss: 0.4888\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - val_loss: 0.4551\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3252 - val_loss: 0.4340\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3157 - val_loss: 0.4056\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2828 - val_loss: 0.3814\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2462 - val_loss: 0.3658\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2233 - val_loss: 0.3304\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1882 - val_loss: 0.3349\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2154 - val_loss: 0.3218\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1762 - val_loss: 0.3081\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1647 - val_loss: 0.2938\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1548 - val_loss: 0.2915\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1467 - val_loss: 0.2821\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1769 - val_loss: 0.2943\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1250 - val_loss: 0.2680\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1285 - val_loss: 0.2745\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1262 - val_loss: 0.2589\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1246 - val_loss: 0.2619\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1174 - val_loss: 0.2650\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1006 - val_loss: 0.2602\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1106 - val_loss: 0.2601\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1292 - val_loss: 0.2594\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0893 - val_loss: 0.2598\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1042 - val_loss: 0.2573\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1066 - val_loss: 0.2597\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1101 - val_loss: 0.2697\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1083 - val_loss: 0.2535\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0911 - val_loss: 0.2625\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1002 - val_loss: 0.2686\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1002 - val_loss: 0.2509\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0940 - val_loss: 0.2614\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1112 - val_loss: 0.2469\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0838 - val_loss: 0.2606\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0841 - val_loss: 0.2490\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0945 - val_loss: 0.2564\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0749 - val_loss: 0.2594\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0904 - val_loss: 0.2425\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0679 - val_loss: 0.2563\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1117 - val_loss: 0.2457\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0648 - val_loss: 0.2460\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0873 - val_loss: 0.2464\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0648 - val_loss: 0.2518\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0614 - val_loss: 0.2366\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0840 - val_loss: 0.2577\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0977 - val_loss: 0.2406\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0757 - val_loss: 0.2369\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0660 - val_loss: 0.2483\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0751 - val_loss: 0.2301\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0598 - val_loss: 0.2449\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0833 - val_loss: 0.2321\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0716 - val_loss: 0.2391\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0651 - val_loss: 0.2290\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0676 - val_loss: 0.2265\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0611 - val_loss: 0.2408\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0610 - val_loss: 0.2199\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0559 - val_loss: 0.2515\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0533 - val_loss: 0.2178\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.2284\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0416 - val_loss: 0.2241\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0511 - val_loss: 0.2239\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.2229\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.2223\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0757 - val_loss: 0.2138\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0841 - val_loss: 0.2312\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0783 - val_loss: 0.2191\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0724 - val_loss: 0.2093\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0430 - val_loss: 0.2137\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0606 - val_loss: 0.2154\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0554 - val_loss: 0.2121\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0537 - val_loss: 0.2062\n",
      "Epoch 80/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0536 - val_loss: 0.2064\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0576 - val_loss: 0.2081\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0602 - val_loss: 0.2013\n",
      "Epoch 83/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0581 - val_loss: 0.2052\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0667 - val_loss: 0.1951\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0621 - val_loss: 0.2030\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0412 - val_loss: 0.1952\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0370 - val_loss: 0.2064\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0788 - val_loss: 0.1939\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0647 - val_loss: 0.2040\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.1837\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.1969\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0473 - val_loss: 0.1866\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0436 - val_loss: 0.1915\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0389 - val_loss: 0.1902\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0431 - val_loss: 0.1824\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0423 - val_loss: 0.1901\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.1812\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0522 - val_loss: 0.1826\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0456 - val_loss: 0.1859\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0433 - val_loss: 0.1886\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0366 - val_loss: 0.1692\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0403 - val_loss: 0.1967\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0455 - val_loss: 0.1711\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0409 - val_loss: 0.1917\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0378 - val_loss: 0.1726\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0242 - val_loss: 0.1907\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0454 - val_loss: 0.1730\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0471 - val_loss: 0.1937\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0328 - val_loss: 0.1660\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0396 - val_loss: 0.1748\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0391 - val_loss: 0.1677\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0301 - val_loss: 0.1824\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0318 - val_loss: 0.1681\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0334 - val_loss: 0.1690\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0461 - val_loss: 0.1733\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0548 - val_loss: 0.1654\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.1758\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0482 - val_loss: 0.1671\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0439 - val_loss: 0.1759\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0330 - val_loss: 0.1608\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0328 - val_loss: 0.1722\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0368 - val_loss: 0.1601\n",
      "Epoch 123/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0279 - val_loss: 0.1651\n",
      "Epoch 124/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.1626\n",
      "Epoch 125/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0349 - val_loss: 0.1556\n",
      "Epoch 126/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0469 - val_loss: 0.1675\n",
      "Epoch 127/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0279 - val_loss: 0.1549\n",
      "Epoch 128/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0409 - val_loss: 0.1659\n",
      "Epoch 129/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0420 - val_loss: 0.1643\n",
      "Epoch 130/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0268 - val_loss: 0.1535\n",
      "Epoch 131/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.1589\n",
      "Epoch 132/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.1577\n",
      "Epoch 133/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0318 - val_loss: 0.1544\n",
      "Epoch 134/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0390 - val_loss: 0.1475\n",
      "Epoch 135/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0531 - val_loss: 0.1690\n",
      "Epoch 136/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0303 - val_loss: 0.1460\n",
      "Epoch 137/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.1512\n",
      "Epoch 138/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.1472\n",
      "Epoch 139/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.1531\n",
      "Epoch 140/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.1470\n",
      "Epoch 141/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0314 - val_loss: 0.1458\n",
      "Epoch 142/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0355 - val_loss: 0.1489\n",
      "Epoch 143/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0264 - val_loss: 0.1478\n",
      "Epoch 144/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.1482\n",
      "Epoch 145/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.1424\n",
      "Epoch 146/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0277 - val_loss: 0.1584\n",
      "Epoch 147/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0221 - val_loss: 0.1412\n",
      "Epoch 148/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.1504\n",
      "Epoch 149/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.1412\n",
      "Epoch 150/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.1518\n",
      "Epoch 151/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.1445\n",
      "Epoch 152/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.1436\n",
      "Epoch 153/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.1535\n",
      "Epoch 154/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.1430\n",
      "Epoch 155/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.1434\n",
      "Epoch 156/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.1495\n",
      "Epoch 157/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.1451\n",
      "Epoch 158/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.1480\n",
      "Epoch 159/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0305 - val_loss: 0.1470\n",
      "Epoch 160/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0238 - val_loss: 0.1418\n",
      "Epoch 161/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0256 - val_loss: 0.1476\n",
      "Epoch 162/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.1472\n",
      "Epoch 163/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0283 - val_loss: 0.1584\n",
      "Epoch 164/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.1512\n",
      "Epoch 165/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.1483\n",
      "Epoch 166/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.1480\n",
      "Epoch 167/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.1631\n",
      "Epoch 168/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.1453\n",
      "Epoch 169/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.1583\n",
      "Epoch 170/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0247 - val_loss: 0.1417\n",
      "Epoch 171/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.1542\n",
      "Epoch 172/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.1475\n",
      "Epoch 173/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.1471\n",
      "Epoch 174/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.1535\n",
      "Epoch 175/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0257 - val_loss: 0.1387\n",
      "Epoch 176/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.1490\n",
      "Epoch 177/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0251 - val_loss: 0.1398\n",
      "Epoch 178/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0262 - val_loss: 0.1631\n",
      "Epoch 179/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.1578\n",
      "Epoch 180/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.1471\n",
      "Epoch 181/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.1661\n",
      "Epoch 182/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.1524\n",
      "Epoch 183/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.1509\n",
      "Epoch 184/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.1519\n",
      "Epoch 185/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0259 - val_loss: 0.1670\n",
      "Epoch 186/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.1523\n",
      "Epoch 187/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.1644\n",
      "Epoch 188/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.1763\n",
      "Epoch 189/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.1534\n",
      "Epoch 190/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.1671\n",
      "Epoch 191/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.1525\n",
      "Epoch 192/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.1710\n",
      "Epoch 193/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.1598\n",
      "Epoch 194/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.1706\n",
      "Epoch 195/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.1732\n",
      "Epoch 196/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.1584\n",
      "Epoch 197/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.1713\n",
      "Epoch 198/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.1606\n",
      "Epoch 199/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.1805\n",
      "Epoch 200/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.1570\n",
      "Epoch 201/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.1703\n",
      "Epoch 202/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0278 - val_loss: 0.1607\n",
      "Epoch 203/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.1664\n",
      "Epoch 204/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.1667\n",
      "Epoch 205/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.1852\n",
      "Epoch 206/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.1647\n",
      "Epoch 207/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.1876\n",
      "Epoch 208/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0204 - val_loss: 0.1617\n",
      "Epoch 209/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0316 - val_loss: 0.1761\n",
      "Epoch 210/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.1689\n",
      "Epoch 211/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0234 - val_loss: 0.1680\n",
      "Epoch 212/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.1659\n",
      "Epoch 213/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0249 - val_loss: 0.1856\n",
      "Epoch 214/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.1748\n",
      "Epoch 215/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.1669\n",
      "Epoch 216/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.1756\n",
      "Epoch 217/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.1754\n",
      "Epoch 218/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.1789\n",
      "Epoch 219/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0170 - val_loss: 0.1738\n",
      "Epoch 220/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.1742\n",
      "Epoch 221/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.1705\n",
      "Epoch 222/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0219 - val_loss: 0.1899\n",
      "Epoch 223/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0297 - val_loss: 0.1633\n",
      "Epoch 224/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0291 - val_loss: 0.1719\n",
      "Epoch 225/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0246 - val_loss: 0.1634\n",
      "Epoch 226/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.1901\n",
      "Epoch 227/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.1680\n",
      "Epoch 228/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0268 - val_loss: 0.1702\n",
      "Epoch 229/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.1799\n",
      "Epoch 230/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.1950\n",
      "Epoch 231/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.1722\n",
      "Epoch 232/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.1893\n",
      "Epoch 233/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.1850\n",
      "Epoch 234/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.1807\n",
      "Epoch 235/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0295 - val_loss: 0.1846\n",
      "Epoch 236/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.1792\n",
      "Epoch 237/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.1943\n",
      "Epoch 238/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.1769\n",
      "Epoch 239/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.2002\n",
      "Epoch 240/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.1820\n",
      "Epoch 241/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.2017\n",
      "Epoch 242/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.1965\n",
      "Epoch 243/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.1791\n",
      "Epoch 244/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.1943\n",
      "Epoch 245/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.1897\n",
      "Epoch 246/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.2008\n",
      "Epoch 247/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.1825\n",
      "Epoch 248/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.2356\n",
      "Epoch 249/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.1928\n",
      "Epoch 250/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.2013\n",
      "Epoch 251/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.2047\n",
      "Epoch 252/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.2125\n",
      "Epoch 253/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.1940\n",
      "Epoch 254/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.1939\n",
      "Epoch 255/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.2314\n",
      "Epoch 256/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.1993\n",
      "Epoch 257/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.1928\n",
      "Epoch 258/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.2140\n",
      "Epoch 259/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.2018\n",
      "Epoch 260/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.2481\n",
      "Epoch 261/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.2074\n",
      "Epoch 262/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0221 - val_loss: 0.2214\n",
      "Epoch 263/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.2101\n",
      "Epoch 264/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.2147\n",
      "Epoch 265/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.2206\n",
      "Epoch 266/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.2017\n",
      "Epoch 267/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.2183\n",
      "Epoch 268/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.2068\n",
      "Epoch 269/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.2105\n",
      "Epoch 270/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.2126\n",
      "Epoch 271/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.2192\n",
      "Epoch 272/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0225 - val_loss: 0.2085\n",
      "Epoch 273/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.2138\n",
      "Epoch 274/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.2070\n",
      "Epoch 275/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.2211\n",
      "Epoch 276/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.2237\n",
      "Epoch 277/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.2418\n",
      "Epoch 278/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.2204\n",
      "Epoch 279/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.2306\n",
      "Epoch 280/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.2391\n",
      "Epoch 281/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.2325\n",
      "Epoch 282/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.2339\n",
      "Epoch 283/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.2514\n",
      "Epoch 284/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.2166\n",
      "Epoch 285/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.2555\n",
      "Epoch 286/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.2360\n",
      "Epoch 287/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.2643\n",
      "Epoch 288/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.2474\n",
      "Epoch 289/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.2559\n",
      "Epoch 290/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.2329\n",
      "Epoch 291/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.2274\n",
      "Epoch 292/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.2348\n",
      "Epoch 293/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.2326\n",
      "Epoch 294/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.2211\n",
      "Epoch 295/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.2237\n",
      "Epoch 296/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.2357\n",
      "Epoch 297/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.2471\n",
      "Epoch 298/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.2480\n",
      "Epoch 299/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.2199\n",
      "Epoch 300/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.2428\n",
      "Epoch 301/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.2285\n",
      "Epoch 302/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.2410\n",
      "Epoch 303/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.2375\n",
      "Epoch 304/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.2648\n",
      "Epoch 305/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.2398\n",
      "Epoch 306/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.2633\n",
      "Epoch 307/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.2452\n",
      "Epoch 308/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.2809\n",
      "Epoch 309/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.2455\n",
      "Epoch 310/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.2672\n",
      "Epoch 311/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.2624\n",
      "Epoch 312/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.2620\n",
      "Epoch 313/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.2801\n",
      "Epoch 314/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.2488\n",
      "Epoch 315/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.3074\n",
      "Epoch 316/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.2485\n",
      "Epoch 317/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.2985\n",
      "Epoch 318/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.2791\n",
      "Epoch 319/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.2471\n",
      "Epoch 320/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.2941\n",
      "Epoch 321/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.2533\n",
      "Epoch 322/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.2876\n",
      "Epoch 323/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.2679\n",
      "Epoch 324/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.2560\n",
      "Epoch 325/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.3062\n",
      "Epoch 326/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.2628\n",
      "Epoch 327/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.3244\n",
      "Epoch 328/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.2642\n",
      "Epoch 329/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.2619\n",
      "Epoch 330/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.2802\n",
      "Epoch 331/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.2709\n",
      "Epoch 332/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.2797\n",
      "Epoch 333/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.2837\n",
      "Epoch 334/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.2711\n",
      "Epoch 335/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.2862\n",
      "Epoch 336/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.2906\n",
      "Epoch 337/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.3163\n",
      "Epoch 338/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.2816\n",
      "Epoch 339/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.3542\n",
      "Epoch 340/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.2960\n",
      "Epoch 341/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.2927\n",
      "Epoch 342/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.3030\n",
      "Epoch 343/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.3122\n",
      "Epoch 344/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.2971\n",
      "Epoch 345/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.2977\n",
      "Epoch 346/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.3000\n",
      "Epoch 347/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.3015\n",
      "Epoch 348/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.2960\n",
      "Epoch 349/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.3174\n",
      "Epoch 350/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.2919\n",
      "Epoch 351/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.3189\n",
      "Epoch 352/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.2937\n",
      "Epoch 353/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.2991\n",
      "Epoch 354/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.3299\n",
      "Epoch 355/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.3013\n",
      "Epoch 356/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.3317\n",
      "Epoch 357/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.3111\n",
      "Epoch 358/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.2933\n",
      "Epoch 359/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.3224\n",
      "Epoch 360/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.3215\n",
      "Epoch 361/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.2954\n",
      "Epoch 362/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.3495\n",
      "Epoch 363/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.2946\n",
      "Epoch 364/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.2954\n",
      "Epoch 365/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.3253\n",
      "Epoch 366/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.3060\n",
      "Epoch 367/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.2970\n",
      "Epoch 368/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.3020\n",
      "Epoch 369/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.2948\n",
      "Epoch 370/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.3106\n",
      "Epoch 371/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.3165\n",
      "Epoch 372/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.3302\n",
      "Epoch 373/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.3113\n",
      "Epoch 374/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.3544\n",
      "Epoch 375/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.3473\n",
      "Epoch 376/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.3541\n",
      "Epoch 377/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.3584\n",
      "Epoch 378/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.3546\n",
      "Epoch 379/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.3313\n",
      "Epoch 380/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.3693\n",
      "Epoch 381/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.3389\n",
      "Epoch 382/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.3500\n",
      "Epoch 383/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.3569\n",
      "Epoch 384/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.3338\n",
      "Epoch 385/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.3278\n",
      "Epoch 386/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.3327\n",
      "Epoch 387/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.3527\n",
      "Epoch 388/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.3169\n",
      "Epoch 389/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.3343\n",
      "Epoch 390/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.3372\n",
      "Epoch 391/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.3521\n",
      "Epoch 392/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.3584\n",
      "Epoch 393/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.3355\n",
      "Epoch 394/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.3262\n",
      "Epoch 395/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.3500\n",
      "Epoch 396/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.3046\n",
      "Epoch 397/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.3572\n",
      "Epoch 398/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.3178\n",
      "Epoch 399/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.3125\n",
      "Epoch 400/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.3377\n",
      "Epoch 401/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.3039\n",
      "Epoch 402/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.3532\n",
      "Epoch 403/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.3053\n",
      "Epoch 404/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.3429\n",
      "Epoch 405/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.3174\n",
      "Epoch 406/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.3578\n",
      "Epoch 407/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.3163\n",
      "Epoch 408/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.3246\n",
      "Epoch 409/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.3327\n",
      "Epoch 410/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.3244\n",
      "Epoch 411/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.3496\n",
      "Epoch 412/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.3052\n",
      "Epoch 413/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.3413\n",
      "Epoch 414/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.3410\n",
      "Epoch 415/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.3008\n",
      "Epoch 416/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.3262\n",
      "Epoch 417/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.3155\n",
      "Epoch 418/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.3323\n",
      "Epoch 419/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.3554\n",
      "Epoch 420/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.3497\n",
      "Epoch 421/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.3276\n",
      "Epoch 422/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.3328\n",
      "Epoch 423/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.3408\n",
      "Epoch 424/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.3548\n",
      "Epoch 425/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.3488\n",
      "Epoch 426/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.3590\n",
      "Epoch 427/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.3360\n",
      "Epoch 428/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.3718\n",
      "Epoch 429/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.3358\n",
      "Epoch 430/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.3484\n",
      "Epoch 431/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.3538\n",
      "Epoch 432/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.3470\n",
      "Epoch 433/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.3424\n",
      "Epoch 434/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.3507\n",
      "Epoch 435/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.3582\n",
      "Epoch 436/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.3305\n",
      "Epoch 437/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.3277\n",
      "Epoch 438/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.3402\n",
      "Epoch 439/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.3311\n",
      "Epoch 440/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.3684\n",
      "Epoch 441/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.3569\n",
      "Epoch 442/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.3702\n",
      "Epoch 443/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.3478\n",
      "Epoch 444/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.3539\n",
      "Epoch 445/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.3471\n",
      "Epoch 446/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.3593\n",
      "Epoch 447/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.3827\n",
      "Epoch 448/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.3863\n",
      "Epoch 449/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.3808\n",
      "Epoch 450/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.4125\n",
      "Epoch 451/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.3682\n",
      "Epoch 452/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.4170\n",
      "Epoch 453/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.4131\n",
      "Epoch 454/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.3885\n",
      "Epoch 455/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.4043\n",
      "Epoch 456/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.3815\n",
      "Epoch 457/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.4159\n",
      "Epoch 458/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.3941\n",
      "Epoch 459/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.4001\n",
      "Epoch 460/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.4152\n",
      "Epoch 461/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.4071\n",
      "Epoch 462/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.4017\n",
      "Epoch 463/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.4598\n",
      "Epoch 464/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.3802\n",
      "Epoch 465/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.4478\n",
      "Epoch 466/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.3816\n",
      "Epoch 467/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.4071\n",
      "Epoch 468/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.4153\n",
      "Epoch 469/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.4081\n",
      "Epoch 470/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.4401\n",
      "Epoch 471/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.4268\n",
      "Epoch 472/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.4304\n",
      "Epoch 473/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.4355\n",
      "Epoch 474/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.4411\n",
      "Epoch 475/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.4261\n",
      "Epoch 476/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.4282\n",
      "Epoch 477/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.4368\n",
      "Epoch 478/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.4476\n",
      "Epoch 479/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.4400\n",
      "Epoch 480/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.4377\n",
      "Epoch 481/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.4181\n",
      "Epoch 482/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.4635\n",
      "Epoch 483/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.4440\n",
      "Epoch 484/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.4351\n",
      "Epoch 485/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.4408\n",
      "Epoch 486/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.4460\n",
      "Epoch 487/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.4453\n",
      "Epoch 488/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.4584\n",
      "Epoch 489/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.4353\n",
      "Epoch 490/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.4474\n",
      "Epoch 491/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.4402\n",
      "Epoch 492/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.4381\n",
      "Epoch 493/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.4336\n",
      "Epoch 494/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.4260\n",
      "Epoch 495/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.4391\n",
      "Epoch 496/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.4444\n",
      "Epoch 497/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.4326\n",
      "Epoch 498/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.4665\n",
      "Epoch 499/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.4695\n",
      "Epoch 500/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.4604\n",
      "Epoch 501/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.4682\n",
      "Epoch 502/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.4532\n",
      "Epoch 503/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.4665\n",
      "Epoch 504/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.4659\n",
      "Epoch 505/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.4510\n",
      "Epoch 506/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.5093\n",
      "Epoch 507/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.4561\n",
      "Epoch 508/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.4589\n",
      "Epoch 509/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.4667\n",
      "Epoch 510/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.4614\n",
      "Epoch 511/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.4789\n",
      "Epoch 512/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.4653\n",
      "Epoch 513/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.4850\n",
      "Epoch 514/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.4882\n",
      "Epoch 515/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.4916\n",
      "Epoch 516/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.4856\n",
      "Epoch 517/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.4872\n",
      "Epoch 518/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.4864\n",
      "Epoch 519/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.4896\n",
      "Epoch 520/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.5041\n",
      "Epoch 521/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.4969\n",
      "Epoch 522/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.5004\n",
      "Epoch 523/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.5033\n",
      "Epoch 524/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.5131\n",
      "Epoch 525/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.5057\n",
      "Epoch 526/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.5169\n",
      "Epoch 527/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.5071\n",
      "Epoch 528/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.5100\n",
      "Epoch 529/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.5100\n",
      "Epoch 530/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.5118\n",
      "Epoch 531/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.5180\n",
      "Epoch 532/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.5205\n",
      "Epoch 533/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.5222\n",
      "Epoch 534/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.5241\n",
      "Epoch 535/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.5274\n",
      "Epoch 536/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.5300\n",
      "Epoch 537/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.5314\n",
      "Epoch 538/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.5334\n",
      "Epoch 539/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.5355\n",
      "Epoch 540/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.5408\n",
      "Epoch 541/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.5415\n",
      "Epoch 542/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.5419\n",
      "Epoch 543/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.5460\n",
      "Epoch 544/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.5503\n",
      "Epoch 545/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.5499\n",
      "Epoch 546/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.5584\n",
      "Epoch 547/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.5561\n",
      "Epoch 548/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.5749\n",
      "Epoch 549/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.5652\n",
      "Epoch 550/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.6045\n",
      "Epoch 551/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.5960\n",
      "Epoch 552/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.6252\n",
      "Epoch 553/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.6025\n",
      "Epoch 554/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.6005\n",
      "Epoch 555/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.5985\n",
      "Epoch 556/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.6156\n",
      "Epoch 557/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.6191\n",
      "Epoch 558/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.6238\n",
      "Epoch 559/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.6143\n",
      "Epoch 560/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.6216\n",
      "Epoch 561/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.6256\n",
      "Epoch 562/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.6290\n",
      "Epoch 563/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.6328\n",
      "Epoch 564/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.6385\n",
      "Epoch 565/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.6240\n",
      "Epoch 566/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.6344\n",
      "Epoch 567/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.6395\n",
      "Epoch 568/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.6440\n",
      "Epoch 569/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.6393\n",
      "Epoch 570/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.6510\n",
      "Epoch 571/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.6429\n",
      "Epoch 572/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.6513\n",
      "Epoch 573/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.6542\n",
      "Epoch 574/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.6568\n",
      "Epoch 575/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.6560\n",
      "Epoch 576/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.6591\n",
      "Epoch 577/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.6707\n",
      "Epoch 578/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.6626\n",
      "Epoch 579/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.6697\n",
      "Epoch 580/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.6705\n",
      "Epoch 581/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.6742\n",
      "Epoch 582/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.6679\n",
      "Epoch 583/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.6765\n",
      "Epoch 584/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.6792\n",
      "Epoch 585/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.6699\n",
      "Epoch 586/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.6902\n",
      "Epoch 587/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.6820\n",
      "Epoch 588/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.6834\n",
      "Epoch 589/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.6851\n",
      "Epoch 590/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.6938\n",
      "Epoch 591/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.6852\n",
      "Epoch 592/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.7056\n",
      "Epoch 593/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.6970\n",
      "Epoch 594/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.6994\n",
      "Epoch 595/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.7270\n",
      "Epoch 596/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.6808\n",
      "Epoch 597/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.7232\n",
      "Epoch 598/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.7033\n",
      "Epoch 599/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.7216\n",
      "Epoch 600/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.7148\n",
      "Epoch 601/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.7292\n",
      "Epoch 602/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.7333\n",
      "Epoch 603/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.7400\n",
      "Epoch 604/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.7373\n",
      "Epoch 605/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.7385\n",
      "Epoch 606/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.7400\n",
      "Epoch 607/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.7434\n",
      "Epoch 608/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.7628\n",
      "Epoch 609/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.7537\n",
      "Epoch 610/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.7594\n",
      "Epoch 611/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.7666\n",
      "Epoch 612/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.7565\n",
      "Epoch 613/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.7767\n",
      "Epoch 614/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.7616\n",
      "Epoch 615/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.8160\n",
      "Epoch 616/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.7563\n",
      "Epoch 617/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.7979\n",
      "Epoch 618/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.7753\n",
      "Epoch 619/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.7733\n",
      "Epoch 620/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.7855\n",
      "Epoch 621/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.7898\n",
      "Epoch 622/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.7747\n",
      "Epoch 623/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.8135\n",
      "Epoch 624/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.7881\n",
      "Epoch 625/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.8210\n",
      "Epoch 626/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.8423\n",
      "Epoch 627/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.8209\n",
      "Epoch 628/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.8182\n",
      "Epoch 629/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.8155\n",
      "Epoch 630/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.8133\n",
      "Epoch 631/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.8200\n",
      "Epoch 632/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.8393\n",
      "Epoch 633/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.8345\n",
      "Epoch 634/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.8405\n",
      "Epoch 635/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.8410\n",
      "Epoch 636/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.8416\n",
      "Epoch 637/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.8548\n",
      "Epoch 638/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.8376\n",
      "Epoch 639/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.8488\n",
      "Epoch 640/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.8577\n",
      "Epoch 641/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.8598\n",
      "Epoch 642/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.8807\n",
      "Epoch 643/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.8723\n",
      "Epoch 644/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.8674\n",
      "Epoch 645/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.8736\n",
      "Epoch 646/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.8898\n",
      "Epoch 647/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.8750\n",
      "Epoch 648/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.9143\n",
      "Epoch 649/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.8648\n",
      "Epoch 650/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.9584\n",
      "Epoch 651/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.9978\n",
      "Epoch 652/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 1.0188\n",
      "Epoch 653/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.9509\n",
      "Epoch 654/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.9686\n",
      "Epoch 655/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.9721\n",
      "Epoch 656/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 1.0023\n",
      "Epoch 657/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.9714\n",
      "Epoch 658/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 1.0192\n",
      "Epoch 659/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.9891\n",
      "Epoch 660/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 1.0006\n",
      "Epoch 661/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 1.0004\n",
      "Epoch 662/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 1.0121\n",
      "Epoch 663/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 1.0127\n",
      "Epoch 664/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 1.0216\n",
      "Epoch 665/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 1.0086\n",
      "Epoch 666/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 1.0105\n",
      "Epoch 667/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 1.0126\n",
      "Epoch 668/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.5688e-04 - val_loss: 1.0169\n",
      "Epoch 669/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 1.0157\n",
      "Epoch 670/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 1.0141\n",
      "Epoch 671/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 1.0183\n",
      "Epoch 672/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 1.0073\n",
      "Epoch 673/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 1.0364\n",
      "Epoch 674/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 1.0009\n",
      "Epoch 675/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 1.0661\n",
      "Epoch 676/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.9543\n",
      "Epoch 677/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.9341\n",
      "Epoch 678/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0263 - val_loss: 1.0200\n",
      "Epoch 679/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0424 - val_loss: 1.0332\n",
      "Epoch 680/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 1.1427\n",
      "Epoch 681/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0352 - val_loss: 1.0342\n",
      "Epoch 682/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.8542\n",
      "Epoch 683/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.9410\n",
      "Epoch 684/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.8503\n",
      "Epoch 685/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.7799\n",
      "Epoch 686/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.8349\n",
      "Epoch 687/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.7901\n",
      "Epoch 688/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.7806\n",
      "Epoch 689/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.8065\n",
      "Epoch 690/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.8083\n",
      "Epoch 691/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.7878\n",
      "Epoch 692/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.8064\n",
      "Epoch 693/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.8042\n",
      "Epoch 694/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.8017\n",
      "Epoch 695/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.8147\n",
      "Epoch 696/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.8053\n",
      "Epoch 697/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.8212\n",
      "Epoch 698/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.8148\n",
      "Epoch 699/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.2921e-04 - val_loss: 0.8205\n",
      "Epoch 700/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7274e-04 - val_loss: 0.8255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1368babe0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y = y_train, epochs=700, validation_data=(x_test, y_test), verbose=1)\n",
    "# bu sefer bilerek overfitting yaptırıcaz o yüzden epochs yüksek verdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6777915954589844,\n",
       "  0.6635583639144897,\n",
       "  0.6480556130409241,\n",
       "  0.6280012130737305,\n",
       "  0.6058741807937622,\n",
       "  0.5781799554824829,\n",
       "  0.5475858449935913,\n",
       "  0.5100464224815369,\n",
       "  0.4687928557395935,\n",
       "  0.42381751537323,\n",
       "  0.37971046566963196,\n",
       "  0.33822640776634216,\n",
       "  0.30253151059150696,\n",
       "  0.27043503522872925,\n",
       "  0.24082911014556885,\n",
       "  0.21736545860767365,\n",
       "  0.20292416214942932,\n",
       "  0.19272252917289734,\n",
       "  0.17827478051185608,\n",
       "  0.16549964249134064,\n",
       "  0.15878093242645264,\n",
       "  0.15101231634616852,\n",
       "  0.15047615766525269,\n",
       "  0.13777633011341095,\n",
       "  0.13629913330078125,\n",
       "  0.12724925577640533,\n",
       "  0.12577632069587708,\n",
       "  0.1206032857298851,\n",
       "  0.11921500414609909,\n",
       "  0.11461041122674942,\n",
       "  0.11160101741552353,\n",
       "  0.10826584696769714,\n",
       "  0.10636309534311295,\n",
       "  0.10386982560157776,\n",
       "  0.10262227803468704,\n",
       "  0.09778699278831482,\n",
       "  0.09825451672077179,\n",
       "  0.09897620230913162,\n",
       "  0.09500382095575333,\n",
       "  0.09280826151371002,\n",
       "  0.09335329383611679,\n",
       "  0.09221894294023514,\n",
       "  0.08747457712888718,\n",
       "  0.08644939959049225,\n",
       "  0.0847143679857254,\n",
       "  0.08353281766176224,\n",
       "  0.08168453723192215,\n",
       "  0.08038964122533798,\n",
       "  0.0795302763581276,\n",
       "  0.07852739095687866,\n",
       "  0.07757683843374252,\n",
       "  0.07614655047655106,\n",
       "  0.0786658525466919,\n",
       "  0.07550434023141861,\n",
       "  0.07343209534883499,\n",
       "  0.07138951122760773,\n",
       "  0.0745806097984314,\n",
       "  0.07138948142528534,\n",
       "  0.07537670433521271,\n",
       "  0.06967256218194962,\n",
       "  0.06883330643177032,\n",
       "  0.06722128391265869,\n",
       "  0.0683327242732048,\n",
       "  0.06628317385911942,\n",
       "  0.06935881078243256,\n",
       "  0.06332974135875702,\n",
       "  0.06399688869714737,\n",
       "  0.06279272586107254,\n",
       "  0.06092941015958786,\n",
       "  0.059619951993227005,\n",
       "  0.05921223759651184,\n",
       "  0.058977171778678894,\n",
       "  0.05862324684858322,\n",
       "  0.06258660554885864,\n",
       "  0.05970824882388115,\n",
       "  0.057633012533187866,\n",
       "  0.05680942162871361,\n",
       "  0.0552840530872345,\n",
       "  0.054450467228889465,\n",
       "  0.05769125372171402,\n",
       "  0.05397627875208855,\n",
       "  0.052583057433366776,\n",
       "  0.05385228618979454,\n",
       "  0.05427630990743637,\n",
       "  0.05139509588479996,\n",
       "  0.0516611784696579,\n",
       "  0.05055772513151169,\n",
       "  0.05328473821282387,\n",
       "  0.04854131117463112,\n",
       "  0.05362846329808235,\n",
       "  0.051090583205223083,\n",
       "  0.04656605422496796,\n",
       "  0.04772341996431351,\n",
       "  0.04889311268925667,\n",
       "  0.04607339948415756,\n",
       "  0.045362457633018494,\n",
       "  0.0472491979598999,\n",
       "  0.052183665335178375,\n",
       "  0.049381401389837265,\n",
       "  0.04869850352406502,\n",
       "  0.050881095230579376,\n",
       "  0.046226900070905685,\n",
       "  0.04395299777388573,\n",
       "  0.043638039380311966,\n",
       "  0.04129673168063164,\n",
       "  0.04359123855829239,\n",
       "  0.04137706384062767,\n",
       "  0.042613543570041656,\n",
       "  0.04003758728504181,\n",
       "  0.03986237198114395,\n",
       "  0.04017600044608116,\n",
       "  0.041609518229961395,\n",
       "  0.03874240070581436,\n",
       "  0.03764849156141281,\n",
       "  0.038479194045066833,\n",
       "  0.03813856095075607,\n",
       "  0.03875681012868881,\n",
       "  0.040370840579271317,\n",
       "  0.03539753332734108,\n",
       "  0.03652707859873772,\n",
       "  0.0368814654648304,\n",
       "  0.038785047829151154,\n",
       "  0.037265144288539886,\n",
       "  0.035305995494127274,\n",
       "  0.03448599949479103,\n",
       "  0.03379306197166443,\n",
       "  0.033561430871486664,\n",
       "  0.03762282431125641,\n",
       "  0.0334165021777153,\n",
       "  0.03246891126036644,\n",
       "  0.032429326325654984,\n",
       "  0.03207741677761078,\n",
       "  0.03468369320034981,\n",
       "  0.035090457648038864,\n",
       "  0.03427492827177048,\n",
       "  0.031819820404052734,\n",
       "  0.03118632361292839,\n",
       "  0.03198136016726494,\n",
       "  0.029666362330317497,\n",
       "  0.032972872257232666,\n",
       "  0.030125588178634644,\n",
       "  0.03064480796456337,\n",
       "  0.029455717653036118,\n",
       "  0.029221830889582634,\n",
       "  0.029501065611839294,\n",
       "  0.028355561196804047,\n",
       "  0.02920532412827015,\n",
       "  0.028731103986501694,\n",
       "  0.029420536011457443,\n",
       "  0.028172506019473076,\n",
       "  0.02723783254623413,\n",
       "  0.027144836261868477,\n",
       "  0.027308683842420578,\n",
       "  0.028356604278087616,\n",
       "  0.02698352560400963,\n",
       "  0.0265976432710886,\n",
       "  0.02654077112674713,\n",
       "  0.02556578442454338,\n",
       "  0.026703689247369766,\n",
       "  0.0261351577937603,\n",
       "  0.028955703601241112,\n",
       "  0.02491658367216587,\n",
       "  0.02476254291832447,\n",
       "  0.02506977692246437,\n",
       "  0.028935300186276436,\n",
       "  0.029438083991408348,\n",
       "  0.024876410141587257,\n",
       "  0.025775179266929626,\n",
       "  0.02457135170698166,\n",
       "  0.025367295369505882,\n",
       "  0.02711995504796505,\n",
       "  0.029357457533478737,\n",
       "  0.025761054828763008,\n",
       "  0.02315983921289444,\n",
       "  0.02721661701798439,\n",
       "  0.023745767772197723,\n",
       "  0.022601503878831863,\n",
       "  0.0229281485080719,\n",
       "  0.023500662297010422,\n",
       "  0.022138312458992004,\n",
       "  0.02303098514676094,\n",
       "  0.02152336947619915,\n",
       "  0.022930046543478966,\n",
       "  0.022539492696523666,\n",
       "  0.028396904468536377,\n",
       "  0.02049986459314823,\n",
       "  0.02146417833864689,\n",
       "  0.02268746681511402,\n",
       "  0.02345261164009571,\n",
       "  0.028897197917103767,\n",
       "  0.02178226411342621,\n",
       "  0.022217316552996635,\n",
       "  0.023014770820736885,\n",
       "  0.022822044789791107,\n",
       "  0.021517522633075714,\n",
       "  0.024739012122154236,\n",
       "  0.026629919186234474,\n",
       "  0.022454172372817993,\n",
       "  0.02523167058825493,\n",
       "  0.020269660279154778,\n",
       "  0.020372288301587105,\n",
       "  0.021118039265275,\n",
       "  0.01980915479362011,\n",
       "  0.020797088742256165,\n",
       "  0.019707083702087402,\n",
       "  0.023683350533246994,\n",
       "  0.01923328824341297,\n",
       "  0.02122320979833603,\n",
       "  0.01870911382138729,\n",
       "  0.01841203309595585,\n",
       "  0.019377106800675392,\n",
       "  0.017807334661483765,\n",
       "  0.020926186814904213,\n",
       "  0.021207410842180252,\n",
       "  0.018651152029633522,\n",
       "  0.018194444477558136,\n",
       "  0.01844368316233158,\n",
       "  0.018104026094079018,\n",
       "  0.0231151282787323,\n",
       "  0.027097031474113464,\n",
       "  0.020188456401228905,\n",
       "  0.01876232586801052,\n",
       "  0.019817283377051353,\n",
       "  0.020412296056747437,\n",
       "  0.01732807233929634,\n",
       "  0.019701145589351654,\n",
       "  0.01729866862297058,\n",
       "  0.017495999112725258,\n",
       "  0.017800794914364815,\n",
       "  0.019164420664310455,\n",
       "  0.016507361084222794,\n",
       "  0.0178676825016737,\n",
       "  0.016940712928771973,\n",
       "  0.01656416431069374,\n",
       "  0.016199354082345963,\n",
       "  0.01708182878792286,\n",
       "  0.017399122938513756,\n",
       "  0.01822926104068756,\n",
       "  0.01768665760755539,\n",
       "  0.015903960913419724,\n",
       "  0.019268855452537537,\n",
       "  0.01848573051393032,\n",
       "  0.015636922791600227,\n",
       "  0.01538461446762085,\n",
       "  0.018884727731347084,\n",
       "  0.01767347939312458,\n",
       "  0.018880564719438553,\n",
       "  0.017813444137573242,\n",
       "  0.016183489933609962,\n",
       "  0.016073083505034447,\n",
       "  0.015579420141875744,\n",
       "  0.01804812252521515,\n",
       "  0.01610576920211315,\n",
       "  0.017862142994999886,\n",
       "  0.014520091004669666,\n",
       "  0.021124476566910744,\n",
       "  0.015820512548089027,\n",
       "  0.016764700412750244,\n",
       "  0.020830824971199036,\n",
       "  0.01638999581336975,\n",
       "  0.015573711134493351,\n",
       "  0.01653415709733963,\n",
       "  0.016033070161938667,\n",
       "  0.014908199198544025,\n",
       "  0.015350991860032082,\n",
       "  0.013845277950167656,\n",
       "  0.01713719218969345,\n",
       "  0.019506283104419708,\n",
       "  0.016675548627972603,\n",
       "  0.015205737203359604,\n",
       "  0.016616715118288994,\n",
       "  0.021654853597283363,\n",
       "  0.01836804859340191,\n",
       "  0.014682083390653133,\n",
       "  0.0143935177475214,\n",
       "  0.015304370783269405,\n",
       "  0.01434553973376751,\n",
       "  0.014988395385444164,\n",
       "  0.014860788360238075,\n",
       "  0.013913779519498348,\n",
       "  0.013899454846978188,\n",
       "  0.014580917544662952,\n",
       "  0.015605256892740726,\n",
       "  0.013171213679015636,\n",
       "  0.015324150212109089,\n",
       "  0.016377078369259834,\n",
       "  0.019768528640270233,\n",
       "  0.014008407481014729,\n",
       "  0.014899834990501404,\n",
       "  0.014831235632300377,\n",
       "  0.014232464134693146,\n",
       "  0.013411718420684338,\n",
       "  0.013816004619002342,\n",
       "  0.014069980941712856,\n",
       "  0.014278450049459934,\n",
       "  0.01631477102637291,\n",
       "  0.014398977160453796,\n",
       "  0.014941959641873837,\n",
       "  0.01563752442598343,\n",
       "  0.013471955433487892,\n",
       "  0.017208123579621315,\n",
       "  0.014005198143422604,\n",
       "  0.013446778059005737,\n",
       "  0.012300573289394379,\n",
       "  0.013221167959272861,\n",
       "  0.014557767659425735,\n",
       "  0.015073772519826889,\n",
       "  0.014528247527778149,\n",
       "  0.014163058251142502,\n",
       "  0.014301245100796223,\n",
       "  0.013114884495735168,\n",
       "  0.013264142908155918,\n",
       "  0.014546268619596958,\n",
       "  0.017131514847278595,\n",
       "  0.018223343417048454,\n",
       "  0.01484597846865654,\n",
       "  0.01188812218606472,\n",
       "  0.013074352405965328,\n",
       "  0.013891992159187794,\n",
       "  0.011760801076889038,\n",
       "  0.01311598252505064,\n",
       "  0.013782409019768238,\n",
       "  0.017170963808894157,\n",
       "  0.0175221748650074,\n",
       "  0.01437519583851099,\n",
       "  0.015475495718419552,\n",
       "  0.011782992631196976,\n",
       "  0.014100433327257633,\n",
       "  0.014610841870307922,\n",
       "  0.015448817051947117,\n",
       "  0.01310812123119831,\n",
       "  0.015544721856713295,\n",
       "  0.013036800548434258,\n",
       "  0.014183521270751953,\n",
       "  0.012808718718588352,\n",
       "  0.013235513120889664,\n",
       "  0.013303123414516449,\n",
       "  0.011496562510728836,\n",
       "  0.012665336951613426,\n",
       "  0.013894612900912762,\n",
       "  0.011958214454352856,\n",
       "  0.013333283364772797,\n",
       "  0.012877262197434902,\n",
       "  0.012960681691765785,\n",
       "  0.011993001215159893,\n",
       "  0.011077935807406902,\n",
       "  0.012468701228499413,\n",
       "  0.01222397293895483,\n",
       "  0.013641810975968838,\n",
       "  0.011829295195639133,\n",
       "  0.011303825303912163,\n",
       "  0.010883733630180359,\n",
       "  0.013332703150808811,\n",
       "  0.012392112985253334,\n",
       "  0.012430441565811634,\n",
       "  0.010466118343174458,\n",
       "  0.011835888028144836,\n",
       "  0.01269768550992012,\n",
       "  0.010998760350048542,\n",
       "  0.012865169905126095,\n",
       "  0.011780386790633202,\n",
       "  0.010653110221028328,\n",
       "  0.011013932526111603,\n",
       "  0.011183331720530987,\n",
       "  0.010669577866792679,\n",
       "  0.011006410233676434,\n",
       "  0.010216832160949707,\n",
       "  0.01136437151581049,\n",
       "  0.010532804764807224,\n",
       "  0.010987049899995327,\n",
       "  0.011452645994722843,\n",
       "  0.009848804213106632,\n",
       "  0.013889620080590248,\n",
       "  0.012691883370280266,\n",
       "  0.010362395085394382,\n",
       "  0.010555153712630272,\n",
       "  0.012248340994119644,\n",
       "  0.010563096031546593,\n",
       "  0.014154264703392982,\n",
       "  0.010260627605021,\n",
       "  0.011371149681508541,\n",
       "  0.009374544955790043,\n",
       "  0.011670625768601894,\n",
       "  0.010707219131290913,\n",
       "  0.01102015282958746,\n",
       "  0.011541304178535938,\n",
       "  0.012254799716174603,\n",
       "  0.011209983378648758,\n",
       "  0.010214082896709442,\n",
       "  0.011945500038564205,\n",
       "  0.01107329223304987,\n",
       "  0.011189534328877926,\n",
       "  0.013818257488310337,\n",
       "  0.011114751920104027,\n",
       "  0.008519532158970833,\n",
       "  0.01139448955655098,\n",
       "  0.009012609720230103,\n",
       "  0.010566586628556252,\n",
       "  0.011384163051843643,\n",
       "  0.012835394591093063,\n",
       "  0.01263858750462532,\n",
       "  0.008704304695129395,\n",
       "  0.009587415494024754,\n",
       "  0.012163585983216763,\n",
       "  0.0108494209125638,\n",
       "  0.008054629899561405,\n",
       "  0.012189479544758797,\n",
       "  0.011770610697567463,\n",
       "  0.009983263909816742,\n",
       "  0.009323266334831715,\n",
       "  0.013497181236743927,\n",
       "  0.010604992508888245,\n",
       "  0.00818149745464325,\n",
       "  0.009720741771161556,\n",
       "  0.008586032316088676,\n",
       "  0.008532105945050716,\n",
       "  0.008864213712513447,\n",
       "  0.009752387180924416,\n",
       "  0.013834302313625813,\n",
       "  0.016039647161960602,\n",
       "  0.011908442713320255,\n",
       "  0.009207632392644882,\n",
       "  0.008222284726798534,\n",
       "  0.00792439840734005,\n",
       "  0.007839586585760117,\n",
       "  0.007947638630867004,\n",
       "  0.00738717382773757,\n",
       "  0.008302459493279457,\n",
       "  0.009853482246398926,\n",
       "  0.008160997182130814,\n",
       "  0.007434946019202471,\n",
       "  0.007528866641223431,\n",
       "  0.007353961933404207,\n",
       "  0.008091450668871403,\n",
       "  0.00899063516408205,\n",
       "  0.01782703585922718,\n",
       "  0.011336326599121094,\n",
       "  0.008081596344709396,\n",
       "  0.008056284859776497,\n",
       "  0.008382321335375309,\n",
       "  0.009386596269905567,\n",
       "  0.00899231992661953,\n",
       "  0.008228338323533535,\n",
       "  0.011028558947145939,\n",
       "  0.008905844762921333,\n",
       "  0.00897571723908186,\n",
       "  0.007954017259180546,\n",
       "  0.007543039042502642,\n",
       "  0.009412077255547047,\n",
       "  0.013987566344439983,\n",
       "  0.005478199105709791,\n",
       "  0.00708506815135479,\n",
       "  0.007426377851516008,\n",
       "  0.007334037683904171,\n",
       "  0.007405679672956467,\n",
       "  0.009003627113997936,\n",
       "  0.00872583594173193,\n",
       "  0.007211621850728989,\n",
       "  0.0068955859169363976,\n",
       "  0.006728635635226965,\n",
       "  0.007762264460325241,\n",
       "  0.01069037988781929,\n",
       "  0.006302386522293091,\n",
       "  0.007800925988703966,\n",
       "  0.009830941446125507,\n",
       "  0.009573441930115223,\n",
       "  0.009758270345628262,\n",
       "  0.006809249985963106,\n",
       "  0.008384852670133114,\n",
       "  0.0073183197528123856,\n",
       "  0.007138009648770094,\n",
       "  0.006404440850019455,\n",
       "  0.00622220803052187,\n",
       "  0.006284924224019051,\n",
       "  0.006230182014405727,\n",
       "  0.006140358280390501,\n",
       "  0.006602690555155277,\n",
       "  0.0071858749724924564,\n",
       "  0.007073524873703718,\n",
       "  0.007997359149158001,\n",
       "  0.006076683755964041,\n",
       "  0.007093664258718491,\n",
       "  0.0063551124185323715,\n",
       "  0.007966277189552784,\n",
       "  0.006820810493081808,\n",
       "  0.006383228115737438,\n",
       "  0.006261949893087149,\n",
       "  0.006365245673805475,\n",
       "  0.005142547190189362,\n",
       "  0.006341337226331234,\n",
       "  0.0069186994805932045,\n",
       "  0.005788884591311216,\n",
       "  0.005633608903735876,\n",
       "  0.006475882604718208,\n",
       "  0.005799322854727507,\n",
       "  0.0064333523623645306,\n",
       "  0.008043430745601654,\n",
       "  0.007572191301733255,\n",
       "  0.006359649356454611,\n",
       "  0.006411537062376738,\n",
       "  0.0074823396280407906,\n",
       "  0.011090452782809734,\n",
       "  0.009952832944691181,\n",
       "  0.00939720869064331,\n",
       "  0.005057003814727068,\n",
       "  0.006040539592504501,\n",
       "  0.009067174047231674,\n",
       "  0.00877273641526699,\n",
       "  0.01046367734670639,\n",
       "  0.0056891068816185,\n",
       "  0.010482055135071278,\n",
       "  0.008642816916108131,\n",
       "  0.005925633013248444,\n",
       "  0.0052018542774021626,\n",
       "  0.005056564696133137,\n",
       "  0.005302708130329847,\n",
       "  0.005621278192847967,\n",
       "  0.005209762137383223,\n",
       "  0.005036267451941967,\n",
       "  0.0046564871445298195,\n",
       "  0.004981541074812412,\n",
       "  0.006752657704055309,\n",
       "  0.006848562508821487,\n",
       "  0.005176406819373369,\n",
       "  0.007695572916418314,\n",
       "  0.0056126113049685955,\n",
       "  0.00430389866232872,\n",
       "  0.006216241046786308,\n",
       "  0.004902097396552563,\n",
       "  0.004813541658222675,\n",
       "  0.004896230064332485,\n",
       "  0.004405137617141008,\n",
       "  0.004400041885674,\n",
       "  0.005258929915726185,\n",
       "  0.0044762371107935905,\n",
       "  0.005066676065325737,\n",
       "  0.004840858280658722,\n",
       "  0.004594925791025162,\n",
       "  0.004491470288485289,\n",
       "  0.003948850557208061,\n",
       "  0.005220048129558563,\n",
       "  0.005430697929114103,\n",
       "  0.0067628552205860615,\n",
       "  0.0072411163710057735,\n",
       "  0.004592574201524258,\n",
       "  0.005203955341130495,\n",
       "  0.008317572996020317,\n",
       "  0.003959240857511759,\n",
       "  0.007412162609398365,\n",
       "  0.007112712133675814,\n",
       "  0.009658139199018478,\n",
       "  0.003472123993560672,\n",
       "  0.007709620054811239,\n",
       "  0.004750562831759453,\n",
       "  0.004374249372631311,\n",
       "  0.004474854562431574,\n",
       "  0.005097488407045603,\n",
       "  0.005221795756369829,\n",
       "  0.003844535443931818,\n",
       "  0.0038874137680977583,\n",
       "  0.004607816692441702,\n",
       "  0.005234977696090937,\n",
       "  0.004475156310945749,\n",
       "  0.005203545093536377,\n",
       "  0.005858260672539473,\n",
       "  0.0057561662979424,\n",
       "  0.005991484969854355,\n",
       "  0.00478404201567173,\n",
       "  0.004079838749021292,\n",
       "  0.00357946683652699,\n",
       "  0.0038531918544322252,\n",
       "  0.00420667789876461,\n",
       "  0.0038125100545585155,\n",
       "  0.0036969727370887995,\n",
       "  0.0038747850339859724,\n",
       "  0.003734092228114605,\n",
       "  0.004436199553310871,\n",
       "  0.00465681916102767,\n",
       "  0.0039445445872843266,\n",
       "  0.0037167775444686413,\n",
       "  0.0036609331145882607,\n",
       "  0.0034361090511083603,\n",
       "  0.0040963985957205296,\n",
       "  0.004967906512320042,\n",
       "  0.002932396251708269,\n",
       "  0.0036746778059750795,\n",
       "  0.00379833672195673,\n",
       "  0.0034159617498517036,\n",
       "  0.0035617074463516474,\n",
       "  0.004695052746683359,\n",
       "  0.0034343358129262924,\n",
       "  0.004502905998378992,\n",
       "  0.004035052843391895,\n",
       "  0.0036525321193039417,\n",
       "  0.007738985121250153,\n",
       "  0.008770791813731194,\n",
       "  0.005798435304313898,\n",
       "  0.005046867299824953,\n",
       "  0.004156337585300207,\n",
       "  0.00318883266299963,\n",
       "  0.003526685992255807,\n",
       "  0.0030250384006649256,\n",
       "  0.0032738924492150545,\n",
       "  0.004190254025161266,\n",
       "  0.003973647020757198,\n",
       "  0.004038157872855663,\n",
       "  0.004345062654465437,\n",
       "  0.0034677553921937943,\n",
       "  0.0039025666192173958,\n",
       "  0.003152484307065606,\n",
       "  0.0035049777943640947,\n",
       "  0.002631036564707756,\n",
       "  0.003189830109477043,\n",
       "  0.004511245992034674,\n",
       "  0.010159910656511784,\n",
       "  0.0048648640513420105,\n",
       "  0.004323666449636221,\n",
       "  0.005190306343138218,\n",
       "  0.0032272625248879194,\n",
       "  0.0027703074738383293,\n",
       "  0.0030830332543700933,\n",
       "  0.0032477667555212975,\n",
       "  0.0037989201955497265,\n",
       "  0.0038478246424347162,\n",
       "  0.003687400370836258,\n",
       "  0.0035564140416681767,\n",
       "  0.003081412287428975,\n",
       "  0.0032528045121580362,\n",
       "  0.0029968968592584133,\n",
       "  0.0029532460030168295,\n",
       "  0.003938536159694195,\n",
       "  0.0026721530593931675,\n",
       "  0.0029676170088350773,\n",
       "  0.0026485559064894915,\n",
       "  0.0026009574066847563,\n",
       "  0.0032303077168762684,\n",
       "  0.0038136786315590143,\n",
       "  0.0032840678468346596,\n",
       "  0.004057573154568672,\n",
       "  0.003215692937374115,\n",
       "  0.0025294788647443056,\n",
       "  0.0027694422751665115,\n",
       "  0.0032623910810798407,\n",
       "  0.00264647020958364,\n",
       "  0.0025803586468100548,\n",
       "  0.0026473565958440304,\n",
       "  0.002868026029318571,\n",
       "  0.0022540059871971607,\n",
       "  0.004433701746165752,\n",
       "  0.00515579292550683,\n",
       "  0.0021415515802800655,\n",
       "  0.003329588333144784,\n",
       "  0.003623418277129531,\n",
       "  0.004089959431439638,\n",
       "  0.004054901655763388,\n",
       "  0.002652245108038187,\n",
       "  0.003201892366632819,\n",
       "  0.0024381629191339016,\n",
       "  0.0019925145898014307,\n",
       "  0.0020244468469172716,\n",
       "  0.0017935585929080844,\n",
       "  0.002031674375757575,\n",
       "  0.002144204219803214,\n",
       "  0.0017093728529289365,\n",
       "  0.001900634728372097,\n",
       "  0.0018534724367782474,\n",
       "  0.0016182796098291874,\n",
       "  0.0015777122462168336,\n",
       "  0.0023650778457522392,\n",
       "  0.0024513036478310823,\n",
       "  0.0031118292827159166,\n",
       "  0.003110704477876425,\n",
       "  0.003990067169070244,\n",
       "  0.005628230515867472,\n",
       "  0.007717786822468042,\n",
       "  0.011536398902535439,\n",
       "  0.014365644194185734,\n",
       "  0.02809085324406624,\n",
       "  0.054867371916770935,\n",
       "  0.006912921089679003,\n",
       "  0.03831285983324051,\n",
       "  0.023280445486307144,\n",
       "  0.011880682781338692,\n",
       "  0.011475374922156334,\n",
       "  0.006370363291352987,\n",
       "  0.0014159235870465636,\n",
       "  0.0028282939456403255,\n",
       "  0.002311314921826124,\n",
       "  0.0016514468006789684,\n",
       "  0.002139505697414279,\n",
       "  0.0016733191441744566,\n",
       "  0.0016281460411846638,\n",
       "  0.0022132722660899162,\n",
       "  0.0016764738829806447,\n",
       "  0.0017254042904824018,\n",
       "  0.0017414530739188194,\n",
       "  0.0017469676677137613,\n",
       "  0.0013714509550482035,\n",
       "  0.0015125996433198452,\n",
       "  0.001478577614761889],\n",
       " 'val_loss': [0.6874654293060303,\n",
       "  0.6826570630073547,\n",
       "  0.6747660040855408,\n",
       "  0.6612022519111633,\n",
       "  0.6525528430938721,\n",
       "  0.6247944831848145,\n",
       "  0.6013585925102234,\n",
       "  0.567054033279419,\n",
       "  0.5315284729003906,\n",
       "  0.4888460040092468,\n",
       "  0.45508715510368347,\n",
       "  0.43402886390686035,\n",
       "  0.40559184551239014,\n",
       "  0.38144877552986145,\n",
       "  0.3658299446105957,\n",
       "  0.3304104804992676,\n",
       "  0.334920197725296,\n",
       "  0.32183972001075745,\n",
       "  0.3081120550632477,\n",
       "  0.2938233017921448,\n",
       "  0.2915492653846741,\n",
       "  0.2820785641670227,\n",
       "  0.29434412717819214,\n",
       "  0.26800572872161865,\n",
       "  0.27448153495788574,\n",
       "  0.25888437032699585,\n",
       "  0.26190030574798584,\n",
       "  0.26499634981155396,\n",
       "  0.26015323400497437,\n",
       "  0.26005351543426514,\n",
       "  0.25935977697372437,\n",
       "  0.2597803473472595,\n",
       "  0.257329523563385,\n",
       "  0.2597379982471466,\n",
       "  0.2697327136993408,\n",
       "  0.2535448670387268,\n",
       "  0.2625415325164795,\n",
       "  0.26862937211990356,\n",
       "  0.25093600153923035,\n",
       "  0.26135388016700745,\n",
       "  0.2468581646680832,\n",
       "  0.2605850100517273,\n",
       "  0.24900972843170166,\n",
       "  0.2564059793949127,\n",
       "  0.25941741466522217,\n",
       "  0.2424517124891281,\n",
       "  0.2562521696090698,\n",
       "  0.24572360515594482,\n",
       "  0.24600709974765778,\n",
       "  0.24642227590084076,\n",
       "  0.2518404722213745,\n",
       "  0.23658190667629242,\n",
       "  0.25773000717163086,\n",
       "  0.24063239991664886,\n",
       "  0.23691540956497192,\n",
       "  0.24832424521446228,\n",
       "  0.230105921626091,\n",
       "  0.24493147432804108,\n",
       "  0.2321368157863617,\n",
       "  0.23913419246673584,\n",
       "  0.22895817458629608,\n",
       "  0.22650335729122162,\n",
       "  0.24079303443431854,\n",
       "  0.21990349888801575,\n",
       "  0.2515287399291992,\n",
       "  0.21778042614459991,\n",
       "  0.2283925563097,\n",
       "  0.22414372861385345,\n",
       "  0.22387033700942993,\n",
       "  0.22294177114963531,\n",
       "  0.22225621342658997,\n",
       "  0.21381407976150513,\n",
       "  0.23124918341636658,\n",
       "  0.21905097365379333,\n",
       "  0.2092704325914383,\n",
       "  0.21369163691997528,\n",
       "  0.2153729945421219,\n",
       "  0.21214847266674042,\n",
       "  0.2061687856912613,\n",
       "  0.20641733705997467,\n",
       "  0.208057701587677,\n",
       "  0.20125462114810944,\n",
       "  0.20519688725471497,\n",
       "  0.19511598348617554,\n",
       "  0.20298990607261658,\n",
       "  0.19521747529506683,\n",
       "  0.20638631284236908,\n",
       "  0.19393883645534515,\n",
       "  0.2040276974439621,\n",
       "  0.183742493391037,\n",
       "  0.19692838191986084,\n",
       "  0.1866261214017868,\n",
       "  0.19149422645568848,\n",
       "  0.1901671141386032,\n",
       "  0.18235458433628082,\n",
       "  0.19014404714107513,\n",
       "  0.18116708099842072,\n",
       "  0.1826288402080536,\n",
       "  0.1858704686164856,\n",
       "  0.1885652393102646,\n",
       "  0.16920194029808044,\n",
       "  0.19674313068389893,\n",
       "  0.17111755907535553,\n",
       "  0.19166119396686554,\n",
       "  0.17255161702632904,\n",
       "  0.19066579639911652,\n",
       "  0.1729782521724701,\n",
       "  0.1936759054660797,\n",
       "  0.16603456437587738,\n",
       "  0.17477336525917053,\n",
       "  0.1677432656288147,\n",
       "  0.18236160278320312,\n",
       "  0.1680838167667389,\n",
       "  0.16896598041057587,\n",
       "  0.17330841720104218,\n",
       "  0.16535858809947968,\n",
       "  0.1758415848016739,\n",
       "  0.1670694798231125,\n",
       "  0.1759396344423294,\n",
       "  0.160796657204628,\n",
       "  0.17216764390468597,\n",
       "  0.16010597348213196,\n",
       "  0.165104478597641,\n",
       "  0.16260561347007751,\n",
       "  0.15564101934432983,\n",
       "  0.16750989854335785,\n",
       "  0.15492689609527588,\n",
       "  0.16585348546504974,\n",
       "  0.1642887443304062,\n",
       "  0.1535007655620575,\n",
       "  0.158893421292305,\n",
       "  0.15769949555397034,\n",
       "  0.15437018871307373,\n",
       "  0.14750158786773682,\n",
       "  0.16896700859069824,\n",
       "  0.14598186314105988,\n",
       "  0.15120866894721985,\n",
       "  0.14718618988990784,\n",
       "  0.15307240188121796,\n",
       "  0.1469872146844864,\n",
       "  0.14581696689128876,\n",
       "  0.14890924096107483,\n",
       "  0.1477845162153244,\n",
       "  0.1482071578502655,\n",
       "  0.14235927164554596,\n",
       "  0.15838493406772614,\n",
       "  0.14123176038265228,\n",
       "  0.15041673183441162,\n",
       "  0.1411665827035904,\n",
       "  0.15179666876792908,\n",
       "  0.14450812339782715,\n",
       "  0.1435808539390564,\n",
       "  0.1535021960735321,\n",
       "  0.14301060140132904,\n",
       "  0.14337356388568878,\n",
       "  0.149529829621315,\n",
       "  0.14505673944950104,\n",
       "  0.14802442491054535,\n",
       "  0.1469901204109192,\n",
       "  0.14180195331573486,\n",
       "  0.14764800667762756,\n",
       "  0.14718659222126007,\n",
       "  0.158431276679039,\n",
       "  0.1512182354927063,\n",
       "  0.14827510714530945,\n",
       "  0.1480075567960739,\n",
       "  0.16311556100845337,\n",
       "  0.14529187977313995,\n",
       "  0.1583258956670761,\n",
       "  0.1416754126548767,\n",
       "  0.15417659282684326,\n",
       "  0.14753113687038422,\n",
       "  0.1471288651227951,\n",
       "  0.15348246693611145,\n",
       "  0.13869771361351013,\n",
       "  0.1489523947238922,\n",
       "  0.13982877135276794,\n",
       "  0.16314426064491272,\n",
       "  0.15782122313976288,\n",
       "  0.14710862934589386,\n",
       "  0.1661004275083542,\n",
       "  0.15238012373447418,\n",
       "  0.15086518228054047,\n",
       "  0.15190833806991577,\n",
       "  0.16697457432746887,\n",
       "  0.152339905500412,\n",
       "  0.16435553133487701,\n",
       "  0.1763044148683548,\n",
       "  0.15343908965587616,\n",
       "  0.16712741553783417,\n",
       "  0.15251849591732025,\n",
       "  0.17099982500076294,\n",
       "  0.15980164706707,\n",
       "  0.17059601843357086,\n",
       "  0.1731826663017273,\n",
       "  0.15841050446033478,\n",
       "  0.1713498830795288,\n",
       "  0.1605958640575409,\n",
       "  0.18049301207065582,\n",
       "  0.1570000797510147,\n",
       "  0.17029410600662231,\n",
       "  0.16065558791160583,\n",
       "  0.16635118424892426,\n",
       "  0.16674740612506866,\n",
       "  0.18520131707191467,\n",
       "  0.16472624242305756,\n",
       "  0.18762622773647308,\n",
       "  0.16172774136066437,\n",
       "  0.1761080026626587,\n",
       "  0.1689230054616928,\n",
       "  0.1680402308702469,\n",
       "  0.16593366861343384,\n",
       "  0.18564561009407043,\n",
       "  0.17479757964611053,\n",
       "  0.16685926914215088,\n",
       "  0.17555250227451324,\n",
       "  0.1754261702299118,\n",
       "  0.1788651943206787,\n",
       "  0.1738060712814331,\n",
       "  0.17422477900981903,\n",
       "  0.1705067902803421,\n",
       "  0.1898936927318573,\n",
       "  0.16326826810836792,\n",
       "  0.17190782725811005,\n",
       "  0.16339567303657532,\n",
       "  0.19014690816402435,\n",
       "  0.16795814037322998,\n",
       "  0.1702023148536682,\n",
       "  0.179925337433815,\n",
       "  0.19501909613609314,\n",
       "  0.17215658724308014,\n",
       "  0.1892920583486557,\n",
       "  0.18497078120708466,\n",
       "  0.1807364970445633,\n",
       "  0.1846405416727066,\n",
       "  0.1791565865278244,\n",
       "  0.19431249797344208,\n",
       "  0.17694054543972015,\n",
       "  0.20020169019699097,\n",
       "  0.18201155960559845,\n",
       "  0.20166586339473724,\n",
       "  0.19649332761764526,\n",
       "  0.17905090749263763,\n",
       "  0.19428271055221558,\n",
       "  0.18967576324939728,\n",
       "  0.20077674090862274,\n",
       "  0.1825084090232849,\n",
       "  0.2355724424123764,\n",
       "  0.1928270310163498,\n",
       "  0.20133449137210846,\n",
       "  0.20472918450832367,\n",
       "  0.21245889365673065,\n",
       "  0.19398784637451172,\n",
       "  0.19389836490154266,\n",
       "  0.23140332102775574,\n",
       "  0.19933481514453888,\n",
       "  0.19282075762748718,\n",
       "  0.2140473872423172,\n",
       "  0.2017885148525238,\n",
       "  0.24810391664505005,\n",
       "  0.2074061930179596,\n",
       "  0.22142648696899414,\n",
       "  0.2100992351770401,\n",
       "  0.21465139091014862,\n",
       "  0.22057560086250305,\n",
       "  0.20173268020153046,\n",
       "  0.21825434267520905,\n",
       "  0.20679770410060883,\n",
       "  0.2104956954717636,\n",
       "  0.21256139874458313,\n",
       "  0.21919237077236176,\n",
       "  0.20847812294960022,\n",
       "  0.21376372873783112,\n",
       "  0.20697298645973206,\n",
       "  0.22109900414943695,\n",
       "  0.22366958856582642,\n",
       "  0.24179382622241974,\n",
       "  0.22041229903697968,\n",
       "  0.23059874773025513,\n",
       "  0.23907509446144104,\n",
       "  0.23250432312488556,\n",
       "  0.23389878869056702,\n",
       "  0.25143367052078247,\n",
       "  0.21658936142921448,\n",
       "  0.2554730176925659,\n",
       "  0.23601573705673218,\n",
       "  0.2643093466758728,\n",
       "  0.24737176299095154,\n",
       "  0.2559240758419037,\n",
       "  0.23286080360412598,\n",
       "  0.22737812995910645,\n",
       "  0.2347850650548935,\n",
       "  0.23264212906360626,\n",
       "  0.22106938064098358,\n",
       "  0.22369031608104706,\n",
       "  0.23567326366901398,\n",
       "  0.24714095890522003,\n",
       "  0.24800287187099457,\n",
       "  0.21993789076805115,\n",
       "  0.24276793003082275,\n",
       "  0.22852890193462372,\n",
       "  0.24101784825325012,\n",
       "  0.23754504323005676,\n",
       "  0.2647615969181061,\n",
       "  0.23977071046829224,\n",
       "  0.26325151324272156,\n",
       "  0.24521352350711823,\n",
       "  0.2808801829814911,\n",
       "  0.24552661180496216,\n",
       "  0.26724299788475037,\n",
       "  0.26238611340522766,\n",
       "  0.2619815170764923,\n",
       "  0.28011593222618103,\n",
       "  0.24878931045532227,\n",
       "  0.30740776658058167,\n",
       "  0.24848149716854095,\n",
       "  0.2984784245491028,\n",
       "  0.27913546562194824,\n",
       "  0.24711453914642334,\n",
       "  0.29413309693336487,\n",
       "  0.2532941699028015,\n",
       "  0.28762656450271606,\n",
       "  0.26787713170051575,\n",
       "  0.256016343832016,\n",
       "  0.30617555975914,\n",
       "  0.26283764839172363,\n",
       "  0.3244286775588989,\n",
       "  0.2641904354095459,\n",
       "  0.26187947392463684,\n",
       "  0.2801806330680847,\n",
       "  0.27088603377342224,\n",
       "  0.2796982228755951,\n",
       "  0.28370171785354614,\n",
       "  0.27110105752944946,\n",
       "  0.28624874353408813,\n",
       "  0.2906448543071747,\n",
       "  0.31631261110305786,\n",
       "  0.2816130220890045,\n",
       "  0.35417985916137695,\n",
       "  0.2960129380226135,\n",
       "  0.2927349805831909,\n",
       "  0.30295053124427795,\n",
       "  0.3122260272502899,\n",
       "  0.2971310615539551,\n",
       "  0.29768142104148865,\n",
       "  0.29997214674949646,\n",
       "  0.3014775216579437,\n",
       "  0.29602310061454773,\n",
       "  0.3174304664134979,\n",
       "  0.29191234707832336,\n",
       "  0.31891950964927673,\n",
       "  0.2936723530292511,\n",
       "  0.29911506175994873,\n",
       "  0.3299150764942169,\n",
       "  0.3012852072715759,\n",
       "  0.3316746950149536,\n",
       "  0.3110950291156769,\n",
       "  0.29327985644340515,\n",
       "  0.3223838210105896,\n",
       "  0.32146862149238586,\n",
       "  0.2954085171222687,\n",
       "  0.3495456576347351,\n",
       "  0.29455721378326416,\n",
       "  0.29543614387512207,\n",
       "  0.3252960741519928,\n",
       "  0.305954247713089,\n",
       "  0.2970346510410309,\n",
       "  0.30201807618141174,\n",
       "  0.29484841227531433,\n",
       "  0.3105851113796234,\n",
       "  0.31652840971946716,\n",
       "  0.3301704227924347,\n",
       "  0.31134283542633057,\n",
       "  0.3543902635574341,\n",
       "  0.34733209013938904,\n",
       "  0.35410407185554504,\n",
       "  0.35835662484169006,\n",
       "  0.354574590921402,\n",
       "  0.3312681019306183,\n",
       "  0.3692958354949951,\n",
       "  0.33892786502838135,\n",
       "  0.3499508798122406,\n",
       "  0.3568560481071472,\n",
       "  0.3338465392589569,\n",
       "  0.32776564359664917,\n",
       "  0.3326866030693054,\n",
       "  0.35266831517219543,\n",
       "  0.3168565332889557,\n",
       "  0.3342517018318176,\n",
       "  0.3371593952178955,\n",
       "  0.3520948886871338,\n",
       "  0.3584314286708832,\n",
       "  0.3355209529399872,\n",
       "  0.3261672854423523,\n",
       "  0.3500165641307831,\n",
       "  0.3045635521411896,\n",
       "  0.35719212889671326,\n",
       "  0.3178325891494751,\n",
       "  0.31246230006217957,\n",
       "  0.33772122859954834,\n",
       "  0.3038780391216278,\n",
       "  0.3531949818134308,\n",
       "  0.3053300678730011,\n",
       "  0.3428701162338257,\n",
       "  0.31739670038223267,\n",
       "  0.3577643930912018,\n",
       "  0.31631889939308167,\n",
       "  0.3246336877346039,\n",
       "  0.33273395895957947,\n",
       "  0.32435500621795654,\n",
       "  0.3495665490627289,\n",
       "  0.30517348647117615,\n",
       "  0.34133365750312805,\n",
       "  0.3409672677516937,\n",
       "  0.3008418083190918,\n",
       "  0.32615193724632263,\n",
       "  0.3155052959918976,\n",
       "  0.33230143785476685,\n",
       "  0.3553992211818695,\n",
       "  0.34972289204597473,\n",
       "  0.3276345729827881,\n",
       "  0.3327840268611908,\n",
       "  0.34082701802253723,\n",
       "  0.35480761528015137,\n",
       "  0.3487934470176697,\n",
       "  0.35903120040893555,\n",
       "  0.3359711170196533,\n",
       "  0.371817946434021,\n",
       "  0.33583351969718933,\n",
       "  0.3483511209487915,\n",
       "  0.35384872555732727,\n",
       "  0.34702029824256897,\n",
       "  0.34236204624176025,\n",
       "  0.35065460205078125,\n",
       "  0.3581865131855011,\n",
       "  0.3304769694805145,\n",
       "  0.3276571035385132,\n",
       "  0.34023529291152954,\n",
       "  0.33114394545555115,\n",
       "  0.3684150278568268,\n",
       "  0.3568924367427826,\n",
       "  0.3701973259449005,\n",
       "  0.34779444336891174,\n",
       "  0.35386523604393005,\n",
       "  0.3470654785633087,\n",
       "  0.35925403237342834,\n",
       "  0.3827328383922577,\n",
       "  0.38632136583328247,\n",
       "  0.38081809878349304,\n",
       "  0.4124884307384491,\n",
       "  0.36822280287742615,\n",
       "  0.41695496439933777,\n",
       "  0.41312867403030396,\n",
       "  0.38851800560951233,\n",
       "  0.40434592962265015,\n",
       "  0.38154730200767517,\n",
       "  0.415930837392807,\n",
       "  0.39413535594940186,\n",
       "  0.40009963512420654,\n",
       "  0.41518503427505493,\n",
       "  0.4071008861064911,\n",
       "  0.40174657106399536,\n",
       "  0.45983242988586426,\n",
       "  0.380248099565506,\n",
       "  0.44782182574272156,\n",
       "  0.381625771522522,\n",
       "  0.40712061524391174,\n",
       "  0.41534993052482605,\n",
       "  0.4081428647041321,\n",
       "  0.44006145000457764,\n",
       "  0.4268106520175934,\n",
       "  0.43038904666900635,\n",
       "  0.4355359673500061,\n",
       "  0.441142737865448,\n",
       "  0.42605793476104736,\n",
       "  0.4281788766384125,\n",
       "  0.43682676553726196,\n",
       "  0.447605699300766,\n",
       "  0.43997228145599365,\n",
       "  0.43768996000289917,\n",
       "  0.4180774986743927,\n",
       "  0.4634568691253662,\n",
       "  0.4439646005630493,\n",
       "  0.43508651852607727,\n",
       "  0.44078826904296875,\n",
       "  0.445993036031723,\n",
       "  0.44527214765548706,\n",
       "  0.4584352970123291,\n",
       "  0.4353112280368805,\n",
       "  0.44744858145713806,\n",
       "  0.44023987650871277,\n",
       "  0.4380769729614258,\n",
       "  0.4335857629776001,\n",
       "  0.4260423183441162,\n",
       "  0.43906453251838684,\n",
       "  0.4444335103034973,\n",
       "  0.4325615167617798,\n",
       "  0.46649369597435,\n",
       "  0.4694812297821045,\n",
       "  0.4604179263114929,\n",
       "  0.46815258264541626,\n",
       "  0.45322588086128235,\n",
       "  0.4664958119392395,\n",
       "  0.46594446897506714,\n",
       "  0.450997918844223,\n",
       "  0.5092671513557434,\n",
       "  0.45611512660980225,\n",
       "  0.45893073081970215,\n",
       "  0.4666837155818939,\n",
       "  0.46139273047447205,\n",
       "  0.47885972261428833,\n",
       "  0.4653245806694031,\n",
       "  0.48502734303474426,\n",
       "  0.4881781339645386,\n",
       "  0.4916103482246399,\n",
       "  0.4855935275554657,\n",
       "  0.48723214864730835,\n",
       "  0.486363023519516,\n",
       "  0.48955851793289185,\n",
       "  0.5041307806968689,\n",
       "  0.49694177508354187,\n",
       "  0.50041264295578,\n",
       "  0.5032628178596497,\n",
       "  0.513091504573822,\n",
       "  0.505742073059082,\n",
       "  0.5169275403022766,\n",
       "  0.5071243643760681,\n",
       "  0.5100222826004028,\n",
       "  0.509986162185669,\n",
       "  0.5118322372436523,\n",
       "  0.5179578065872192,\n",
       "  0.5204553604125977,\n",
       "  0.5222064852714539,\n",
       "  0.5240911841392517,\n",
       "  0.5273623466491699,\n",
       "  0.5299669504165649,\n",
       "  0.531449019908905,\n",
       "  0.5333974957466125,\n",
       "  0.5355066657066345,\n",
       "  0.5408413410186768,\n",
       "  0.5415270924568176,\n",
       "  0.5418615341186523,\n",
       "  0.5460490584373474,\n",
       "  0.5502960681915283,\n",
       "  0.549926221370697,\n",
       "  0.558379590511322,\n",
       "  0.556053876876831,\n",
       "  0.5748994946479797,\n",
       "  0.5651901960372925,\n",
       "  0.6045498251914978,\n",
       "  0.5959789156913757,\n",
       "  0.6252219080924988,\n",
       "  0.6025024652481079,\n",
       "  0.6004787087440491,\n",
       "  0.5984671711921692,\n",
       "  0.6155577301979065,\n",
       "  0.6191380620002747,\n",
       "  0.6238425970077515,\n",
       "  0.6143369078636169,\n",
       "  0.6215724945068359,\n",
       "  0.625593364238739,\n",
       "  0.6289785504341125,\n",
       "  0.632750928401947,\n",
       "  0.6385352611541748,\n",
       "  0.6239843368530273,\n",
       "  0.6344054937362671,\n",
       "  0.6394930481910706,\n",
       "  0.6439769864082336,\n",
       "  0.639330267906189,\n",
       "  0.6509668827056885,\n",
       "  0.6429272294044495,\n",
       "  0.6513403058052063,\n",
       "  0.6542212963104248,\n",
       "  0.6567519903182983,\n",
       "  0.6560190320014954,\n",
       "  0.659142255783081,\n",
       "  0.6706662774085999,\n",
       "  0.6626299023628235,\n",
       "  0.6696619391441345,\n",
       "  0.6705060601234436,\n",
       "  0.6742127537727356,\n",
       "  0.6678801774978638,\n",
       "  0.6764771938323975,\n",
       "  0.6792079210281372,\n",
       "  0.6699383854866028,\n",
       "  0.6902295351028442,\n",
       "  0.6819599270820618,\n",
       "  0.6833562850952148,\n",
       "  0.6850830316543579,\n",
       "  0.6937863826751709,\n",
       "  0.6851797103881836,\n",
       "  0.7056061029434204,\n",
       "  0.6969613432884216,\n",
       "  0.6994056701660156,\n",
       "  0.7270452976226807,\n",
       "  0.6807897686958313,\n",
       "  0.7231763005256653,\n",
       "  0.7032971382141113,\n",
       "  0.7216033339500427,\n",
       "  0.7148145437240601,\n",
       "  0.7292419672012329,\n",
       "  0.7332717180252075,\n",
       "  0.7400447726249695,\n",
       "  0.7372674942016602,\n",
       "  0.7385207414627075,\n",
       "  0.7399904131889343,\n",
       "  0.7433717250823975,\n",
       "  0.7627715468406677,\n",
       "  0.7536768317222595,\n",
       "  0.7594425678253174,\n",
       "  0.7666416764259338,\n",
       "  0.7564918994903564,\n",
       "  0.7767355442047119,\n",
       "  0.7616221904754639,\n",
       "  0.8160459399223328,\n",
       "  0.7562710642814636,\n",
       "  0.7978772521018982,\n",
       "  0.7753282785415649,\n",
       "  0.7732728719711304,\n",
       "  0.7854874134063721,\n",
       "  0.7897940874099731,\n",
       "  0.7746683955192566,\n",
       "  0.8134727478027344,\n",
       "  0.7880938649177551,\n",
       "  0.8210192322731018,\n",
       "  0.8423300981521606,\n",
       "  0.8209148049354553,\n",
       "  0.8182320594787598,\n",
       "  0.8154777884483337,\n",
       "  0.8132636547088623,\n",
       "  0.8200029730796814,\n",
       "  0.8393177390098572,\n",
       "  0.8345048427581787,\n",
       "  0.8405470252037048,\n",
       "  0.8409608006477356,\n",
       "  0.8415712118148804,\n",
       "  0.8547918796539307,\n",
       "  0.8375934958457947,\n",
       "  0.8487855792045593,\n",
       "  0.8576905131340027,\n",
       "  0.8598458170890808,\n",
       "  0.8806749582290649,\n",
       "  0.8722500801086426,\n",
       "  0.8674492239952087,\n",
       "  0.8736194968223572,\n",
       "  0.889753520488739,\n",
       "  0.8750073909759521,\n",
       "  0.9142643809318542,\n",
       "  0.8648195862770081,\n",
       "  0.958419144153595,\n",
       "  0.9977774620056152,\n",
       "  1.018803358078003,\n",
       "  0.9509173035621643,\n",
       "  0.9685984253883362,\n",
       "  0.9721448421478271,\n",
       "  1.0023071765899658,\n",
       "  0.9713842272758484,\n",
       "  1.0191640853881836,\n",
       "  0.9890790581703186,\n",
       "  1.0005635023117065,\n",
       "  1.0004059076309204,\n",
       "  1.0121383666992188,\n",
       "  1.0126700401306152,\n",
       "  1.021612286567688,\n",
       "  1.0085586309432983,\n",
       "  1.0104751586914062,\n",
       "  1.0125980377197266,\n",
       "  1.016932725906372,\n",
       "  1.0157341957092285,\n",
       "  1.0141249895095825,\n",
       "  1.018337368965149,\n",
       "  1.0073192119598389,\n",
       "  1.0363503694534302,\n",
       "  1.0009132623672485,\n",
       "  1.0660593509674072,\n",
       "  0.954302966594696,\n",
       "  0.9341483116149902,\n",
       "  1.0199881792068481,\n",
       "  1.0331511497497559,\n",
       "  1.1426790952682495,\n",
       "  1.0342172384262085,\n",
       "  0.854232132434845,\n",
       "  0.9410328269004822,\n",
       "  0.8502854108810425,\n",
       "  0.7799404263496399,\n",
       "  0.8348901867866516,\n",
       "  0.790126383304596,\n",
       "  0.7805561423301697,\n",
       "  0.8064841628074646,\n",
       "  0.8082952499389648,\n",
       "  0.787790834903717,\n",
       "  0.8064048886299133,\n",
       "  0.8041903376579285,\n",
       "  0.8016719818115234,\n",
       "  0.8146587014198303,\n",
       "  0.8052672147750854,\n",
       "  0.8212168216705322,\n",
       "  0.8147551417350769,\n",
       "  0.8204512000083923,\n",
       "  0.825501024723053]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history\n",
    "# json formatında yani sözlük formatında görebiliyoruz bunu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelKaybi = pd.DataFrame(model.history.history)\n",
    "# DataFrame formatına dönüştürdük\n",
    "modelKaybi.plot()\n",
    "# bu şeyi çizdirince overfitting yaptığını görüyoruz.\n",
    "# Biz bunu engellemek için ve aynı zamanda da optimum epoch değerini bulmak için earlystopping sınıfını kullanıyoruz.\n",
    "# Bunun mantığı şöyle early stopping ile val_loss ile normal loss böyle ayrılmaya başladığı anda durduruyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=25)\n",
    "# monitor hangi değerin izleneceği, mode=min seçtik, vebose = 1 ayrıntı göster, patience=25 kaçtane epoch olacağı modelde\n",
    "# gelişme olmadan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 1s 29ms/step - loss: 0.7096 - val_loss: 0.6811\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6771 - val_loss: 0.6667\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6538 - val_loss: 0.6498\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6285 - val_loss: 0.6289\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6024 - val_loss: 0.6025\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5740 - val_loss: 0.5757\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5375 - val_loss: 0.5430\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4939 - val_loss: 0.5121\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4574 - val_loss: 0.4830\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3955 - val_loss: 0.4442\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3656 - val_loss: 0.4202\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3198 - val_loss: 0.3895\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2870 - val_loss: 0.3710\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2643 - val_loss: 0.3558\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2274 - val_loss: 0.3403\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2080 - val_loss: 0.3266\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2054 - val_loss: 0.3212\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1614 - val_loss: 0.3048\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1808 - val_loss: 0.3029\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1867 - val_loss: 0.2860\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1652 - val_loss: 0.2927\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1664 - val_loss: 0.2702\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1654 - val_loss: 0.2706\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1398 - val_loss: 0.2754\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1316 - val_loss: 0.2619\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1277 - val_loss: 0.2569\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1245 - val_loss: 0.2682\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1122 - val_loss: 0.2522\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1116 - val_loss: 0.2517\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1378 - val_loss: 0.2562\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1212 - val_loss: 0.2497\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0914 - val_loss: 0.2505\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1138 - val_loss: 0.2469\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0980 - val_loss: 0.2602\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1156 - val_loss: 0.2477\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1072 - val_loss: 0.2546\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0940 - val_loss: 0.2427\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0951 - val_loss: 0.2405\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0979 - val_loss: 0.2490\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0912 - val_loss: 0.2361\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1006 - val_loss: 0.2408\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0950 - val_loss: 0.2381\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0865 - val_loss: 0.2330\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0722 - val_loss: 0.2419\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1093 - val_loss: 0.2408\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0681 - val_loss: 0.2328\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0763 - val_loss: 0.2468\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0598 - val_loss: 0.2292\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0709 - val_loss: 0.2348\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0896 - val_loss: 0.2349\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0961 - val_loss: 0.2290\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0869 - val_loss: 0.2341\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0668 - val_loss: 0.2227\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0720 - val_loss: 0.2256\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0622 - val_loss: 0.2214\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0948 - val_loss: 0.2293\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0487 - val_loss: 0.2176\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0864 - val_loss: 0.2292\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0870 - val_loss: 0.2152\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0782 - val_loss: 0.2324\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0707 - val_loss: 0.2236\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0489 - val_loss: 0.2135\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0678 - val_loss: 0.2184\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0668 - val_loss: 0.2069\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0712 - val_loss: 0.2105\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0693 - val_loss: 0.2158\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.2194\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0778 - val_loss: 0.2183\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0672 - val_loss: 0.1996\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0793 - val_loss: 0.2179\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0498 - val_loss: 0.2067\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.1997\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0560 - val_loss: 0.2020\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0562 - val_loss: 0.2019\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0555 - val_loss: 0.1920\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0555 - val_loss: 0.2014\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0432 - val_loss: 0.1950\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0565 - val_loss: 0.2051\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.1861\n",
      "Epoch 80/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0606 - val_loss: 0.2015\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0627 - val_loss: 0.1887\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0528 - val_loss: 0.2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0389 - val_loss: 0.1853\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 0.1920\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0417 - val_loss: 0.1823\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.1977\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0646 - val_loss: 0.2064\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0627 - val_loss: 0.1832\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0449 - val_loss: 0.1849\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0397 - val_loss: 0.1817\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.1857\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0510 - val_loss: 0.1940\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.1845\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0393 - val_loss: 0.1843\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0545 - val_loss: 0.1810\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.1829\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0606 - val_loss: 0.1841\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0455 - val_loss: 0.1839\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0564 - val_loss: 0.1867\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.1727\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0422 - val_loss: 0.1847\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0557 - val_loss: 0.1676\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.1746\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.1688\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.1711\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0350 - val_loss: 0.1814\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0314 - val_loss: 0.1638\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.1862\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0255 - val_loss: 0.1657\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0320 - val_loss: 0.1780\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.1743\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0361 - val_loss: 0.1698\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.1678\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0331 - val_loss: 0.1791\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0421 - val_loss: 0.1607\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0360 - val_loss: 0.1714\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.1687\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.1677\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.1718\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.1662\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.1642\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0247 - val_loss: 0.1825\n",
      "Epoch 123/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.1618\n",
      "Epoch 124/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0346 - val_loss: 0.1810\n",
      "Epoch 125/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.1619\n",
      "Epoch 126/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0461 - val_loss: 0.1577\n",
      "Epoch 127/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.1920\n",
      "Epoch 128/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.1501\n",
      "Epoch 129/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.1560\n",
      "Epoch 130/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.1606\n",
      "Epoch 131/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.1558\n",
      "Epoch 132/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.1904\n",
      "Epoch 133/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.1578\n",
      "Epoch 134/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0479 - val_loss: 0.1970\n",
      "Epoch 135/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0334 - val_loss: 0.1644\n",
      "Epoch 136/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.1758\n",
      "Epoch 137/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.1616\n",
      "Epoch 138/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.1877\n",
      "Epoch 139/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.1540\n",
      "Epoch 140/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.1596\n",
      "Epoch 141/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.1740\n",
      "Epoch 142/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0385 - val_loss: 0.1543\n",
      "Epoch 143/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.1815\n",
      "Epoch 144/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.1663\n",
      "Epoch 145/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.1798\n",
      "Epoch 146/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.1721\n",
      "Epoch 147/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.1672\n",
      "Epoch 148/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.1679\n",
      "Epoch 149/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.1674\n",
      "Epoch 150/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.1703\n",
      "Epoch 151/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.1734\n",
      "Epoch 152/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0378 - val_loss: 0.1980\n",
      "Epoch 153/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.1665\n",
      "Epoch 00153: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f137de71c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs=700, validation_data=(x_test, y_test), verbose=1, callbacks=[earlyStopping])\n",
    "# callBacks fonksiyonu bizim kendimiz vermemizz gerek biz de yukarıda oluşturduğumuz earlyStopping fonksiyonunu verdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yukarıda yaptığımız işlemde biz epoch saysını 700 verdik ama bu 700 defa çalışmadı çünkü earlyStopping fonksiyonumuz \n",
    "# sayesinde epoch 153 olduğunda durdu, ve böylece overfitting olmadı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelKaybi = pd.DataFrame(model.history.history)\n",
    "modelKaybi.plot()\n",
    "# graifkte de göründüğü gibi baya bir iyileşme var modelimizde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biz şimdi bir tane daha iyileştirme fonksiyonu yapacağız bu ise şöyle bir şey bu seferde katmanlar ile ilgili bir\n",
    "# overfitting sorunu yaşıyorsak bunu engellemek için drop out kullanıcaz bu veri eğitilirken gerekli gördüğü yerde \n",
    "# katmanları atıcak ve overfittingi engellicek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30, activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\")\n",
    "\n",
    "# bu sefer drop out ekledik modelimize bunun sayısını 1 yaparsak hepsini atar 0 yaparsak etkisi olmaz\n",
    "# genellikle 0.50 ile denenir 0.50'nin üzerinde uyarı verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 1s 26ms/step - loss: 0.6857 - val_loss: 0.6921\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6976 - val_loss: 0.6892\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6678 - val_loss: 0.6868\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6960 - val_loss: 0.6847\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6782 - val_loss: 0.6825\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6808 - val_loss: 0.6808\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6736 - val_loss: 0.6789\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6711 - val_loss: 0.6773\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6812 - val_loss: 0.6754\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6396 - val_loss: 0.6739\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6451 - val_loss: 0.6722\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6517 - val_loss: 0.6705\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6440 - val_loss: 0.6683\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6390 - val_loss: 0.6652\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6226 - val_loss: 0.6631\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6321 - val_loss: 0.6608\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6457 - val_loss: 0.6579\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6288 - val_loss: 0.6540\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6154 - val_loss: 0.6508\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6323 - val_loss: 0.6459\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6531 - val_loss: 0.6424\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6115 - val_loss: 0.6405\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5951 - val_loss: 0.6384\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6026 - val_loss: 0.6361\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5950 - val_loss: 0.6300\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6055 - val_loss: 0.6270\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5830 - val_loss: 0.6240\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6039 - val_loss: 0.6157\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5515 - val_loss: 0.6068\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5872 - val_loss: 0.6004\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5674 - val_loss: 0.5986\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5703 - val_loss: 0.5912\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5625 - val_loss: 0.5841\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5426 - val_loss: 0.5784\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5458 - val_loss: 0.5802\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5294 - val_loss: 0.5729\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5299 - val_loss: 0.5637\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5206 - val_loss: 0.5560\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5582 - val_loss: 0.5502\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5314 - val_loss: 0.5482\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5355 - val_loss: 0.5359\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5125 - val_loss: 0.5257\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4983 - val_loss: 0.5203\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5295 - val_loss: 0.5133\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4876 - val_loss: 0.5046\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4770 - val_loss: 0.4991\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4735 - val_loss: 0.4897\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4689 - val_loss: 0.4771\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4772 - val_loss: 0.4807\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4707 - val_loss: 0.4695\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4212 - val_loss: 0.4457\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4428 - val_loss: 0.4510\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4286 - val_loss: 0.4473\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4834 - val_loss: 0.4352\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4347 - val_loss: 0.4220\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3976 - val_loss: 0.4164\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4273 - val_loss: 0.4298\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4219 - val_loss: 0.3974\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3999 - val_loss: 0.3980\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3981 - val_loss: 0.4051\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - val_loss: 0.4018\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3636 - val_loss: 0.3842\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3494 - val_loss: 0.3689\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - val_loss: 0.3698\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3347 - val_loss: 0.3770\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3535 - val_loss: 0.3706\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3700 - val_loss: 0.3671\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3609 - val_loss: 0.3683\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3606 - val_loss: 0.3487\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3315 - val_loss: 0.3499\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3724 - val_loss: 0.3750\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3658 - val_loss: 0.3804\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3471 - val_loss: 0.3619\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3565 - val_loss: 0.3504\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3366 - val_loss: 0.3489\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3400 - val_loss: 0.3319\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3290 - val_loss: 0.3235\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3545 - val_loss: 0.3314\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3251 - val_loss: 0.3574\n",
      "Epoch 80/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2879 - val_loss: 0.3331\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2764 - val_loss: 0.3308\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2766 - val_loss: 0.3088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2791 - val_loss: 0.2942\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3096 - val_loss: 0.2967\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3433 - val_loss: 0.3283\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3030 - val_loss: 0.3441\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.214 - 0s 7ms/step - loss: 0.2866 - val_loss: 0.3114\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3098 - val_loss: 0.2842\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2854 - val_loss: 0.2885\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2840 - val_loss: 0.3036\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2768 - val_loss: 0.3078\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2859 - val_loss: 0.2846\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2617 - val_loss: 0.2867\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2647 - val_loss: 0.2959\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2503 - val_loss: 0.2920\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2975 - val_loss: 0.2829\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2329 - val_loss: 0.2944\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2399 - val_loss: 0.2965\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2534 - val_loss: 0.2832\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2474 - val_loss: 0.2775\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2778 - val_loss: 0.2765\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2251 - val_loss: 0.2759\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2289 - val_loss: 0.2836\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2643 - val_loss: 0.2834\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2558 - val_loss: 0.2973\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3382 - val_loss: 0.2737\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2506 - val_loss: 0.2765\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2093 - val_loss: 0.2712\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2445 - val_loss: 0.2690\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2449 - val_loss: 0.2763\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2482 - val_loss: 0.2797\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2530 - val_loss: 0.2888\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1974 - val_loss: 0.2898\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2548 - val_loss: 0.2852\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2670 - val_loss: 0.2756\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2448 - val_loss: 0.2696\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2180 - val_loss: 0.2720\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2325 - val_loss: 0.2665\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2237 - val_loss: 0.2729\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2025 - val_loss: 0.2907\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2113 - val_loss: 0.2825\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2348 - val_loss: 0.2775\n",
      "Epoch 123/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2087 - val_loss: 0.2635\n",
      "Epoch 124/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2721 - val_loss: 0.2542\n",
      "Epoch 125/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1909 - val_loss: 0.2608\n",
      "Epoch 126/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1780 - val_loss: 0.2699\n",
      "Epoch 127/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2027 - val_loss: 0.2744\n",
      "Epoch 128/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1988 - val_loss: 0.2751\n",
      "Epoch 129/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1768 - val_loss: 0.2761\n",
      "Epoch 130/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1755 - val_loss: 0.2846\n",
      "Epoch 131/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2083 - val_loss: 0.2922\n",
      "Epoch 132/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2085 - val_loss: 0.2919\n",
      "Epoch 133/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1501 - val_loss: 0.2972\n",
      "Epoch 134/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1935 - val_loss: 0.2907\n",
      "Epoch 135/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1904 - val_loss: 0.3023\n",
      "Epoch 136/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1852 - val_loss: 0.2926\n",
      "Epoch 137/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2469 - val_loss: 0.2870\n",
      "Epoch 138/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2099 - val_loss: 0.2847\n",
      "Epoch 139/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1830 - val_loss: 0.2850\n",
      "Epoch 140/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2166 - val_loss: 0.2844\n",
      "Epoch 141/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2047 - val_loss: 0.2930\n",
      "Epoch 142/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1805 - val_loss: 0.3021\n",
      "Epoch 143/700\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2353 - val_loss: 0.2938\n",
      "Epoch 144/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1913 - val_loss: 0.2840\n",
      "Epoch 145/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1817 - val_loss: 0.2956\n",
      "Epoch 146/700\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1805 - val_loss: 0.2864\n",
      "Epoch 147/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1688 - val_loss: 0.2875\n",
      "Epoch 148/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1919 - val_loss: 0.2899\n",
      "Epoch 149/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2005 - val_loss: 0.2918\n",
      "Epoch 00149: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1383f3c40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs=700, validation_data=(x_test, y_test), verbose=1, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABIo0lEQVR4nO3dd3gVVfrA8e+5N7333kMIvYZeFEQBUUFFxd5d+65r/9nbrrvu6upa0LUjiooNKyCgCNJCDyGQEAgppPfezu+PuQkJSSBgOu/nefKYO3Nm7jvBvPfknTPnKK01Qgghej9TdwcghBCiY0hCF0KIPkISuhBC9BGS0IUQoo+QhC6EEH2EVXe9sZeXlw4LC+uutxdCiF5p69atuVpr79b2dVtCDwsLIzY2trveXggheiWlVEpb+6TkIoQQfYQkdCGE6CMkoQshRB/Rrhq6UmoW8DJgBt7WWj9/zP77gSubnHMg4K21zu/AWIUQfUBNTQ1paWlUVlZ2dyg9mp2dHUFBQVhbW7f7mBMmdKWUGXgNOBtIA7YopZZpreMb2mitXwBesLQ/H7hHkrkQojVpaWk4OzsTFhaGUqq7w+mRtNbk5eWRlpZGeHh4u49rT8llLJCktU7WWlcDS4C5x2l/OfBJuyMQQpxWKisr8fT0lGR+HEopPD09T/qvmPYk9EAgtcnrNMu21oJwAGYBX7Sx/xalVKxSKjYnJ+ekAhVC9B2SzE/sVH5G7UnorZ21rTl3zwfWt1Vu0Vq/pbWO0VrHeHu3Oi7+hPLLqnn623hKq2pP6XghhOir2pPQ04DgJq+DgIw22i6gk8stm+KTcNz0Ipe8vIKdqYWd+VZCiD7Kycmpu0PoFO1J6FuAKKVUuFLKBiNpLzu2kVLKFTgD+KZjQ2xutvVO7rX6nI/L/8S3bz5KbGJ6Z76dEEL0GidM6FrrWuBOYDmwF/hMa71HKXWrUurWJk0vBFZorcs6J1SLEZfDTatxChnOo1aL6Ld4HNUrnoYiSexCiJOjteb+++9nyJAhDB06lE8//RSAI0eOMHXqVEaMGMGQIUP47bffqKur47rrrmts+9JLL3Vz9C21axy61voH4Idjti085vX7wPsdFdhxBY3G+obviN/wI+k/vMBZv78IG16CfmfDqGug/0wwt3/sphCiezz17R7iM4o79JyDAlx44vzB7Wr75ZdfsmPHDnbu3Elubi5jxoxh6tSpfPzxx8ycOZNHHnmEuro6ysvL2bFjB+np6cTFxQFQWFjYoXF3hG6bnKsjDJowm6W5oTz9+0Ye9o1leupK7BKXg6MPDJoLA8+D0EmS3IUQrVq3bh2XX345ZrMZX19fzjjjDLZs2cKYMWO44YYbqKmpYd68eYwYMYKIiAiSk5O56667mDNnDuecc053h99Cr07oAA/MisbarHh8WzB3lc5ips1ublEbGLZ9EaYt/wM7N4ieDQPOg8jpYOPQ3SELISza25PuLFq3PmBv6tSprF27lu+//56rr76a+++/n2uuuYadO3eyfPlyXnvtNT777DPefffdLo74+Hp9QrezNvPwuQO5b2Y06xJzWREfxlU7Ywhxhs/PrsDxwI+w7wfY+QlYOxhJfeD5RlnG3r27wxdCdKOpU6fy5ptvcu2115Kfn8/atWt54YUXSElJITAwkJtvvpmysjK2bdvGueeei42NDRdffDGRkZFcd9113R1+C70+oTewNpuYNsCHaQN8mDsikKvf2cSftvgzqd8DrHa+gntjchlftQESvoeE78BkBWGTjZ77gPPAxb+7L0EI0cUuvPBCNmzYwPDhw1FK8c9//hM/Pz8++OADXnjhBaytrXFycuLDDz8kPT2d66+/nvr6egD+/ve/d3P0Lam2/uTobDExMbozF7j4LDaVB5buAsDZ1gpbaxO/3D8NJ2sTZGyHhG9h73eQl2gcEBhj1NwHzQOP9s+dIIQ4OXv37mXgwIHdHUav0NrPSim1VWsd01r7PtNDP9alMcEEudsT5OZAfnk1815bzxu/JHH/zAEQNNr4mvEk5OyDvd8avfafnzS++s2ACXcY5RkhhOgl+vR86BMjvQjxdGBEsBvzRgTwv98OklZQ3ryRdzRMvQ9u+QX+EgdnPASZcbDoQvjoYsiKb/XcQgjR0/TphN7U/bMGYFJw6cINfLszo/W7227BMO1h+MtuOOc5SN0Cb0yA98+DuC+gtrrrAxdCiHY6bRJ6oJs9i28aj5uDDXd9sp0Xlu9ru7GVDUy8E+7eDmc9DoUpsPQGeHEg/PwUlMtU70KInue0SegAo0Pd+fauycwa7MeijSlUVNcd/wBHT5hyL9y9E678AkLGw7qX4OXh8Nu/oa6mawIXQoh2OK0SOoDZpLh+UhgllbV8v/tIs305JVXkl7VSVjGZIGoGLFgMt/1uDHdc9TS8dy4UHu6iyIUQ4vhOu4QOMDbcgwhvR5ZsNpLxztRCbl+8lfF/X8X8N36ntq6+7YN9B8Hln8DF70D2XnhjMmxcKL11IUS3Oy0TulKKy8eEEJtSwFPf7uGiN37n9wN5nDPIl+TcMr7d1dZ0700MnQ+3roXAUfDTg7BwMuQmdn7wQogudby50w8dOsSQIUO6MJrjOy0TOsBFowKxNiveW3+Icwb5svaBabx2xSiifZ15dXUSdfXteODKIwKu/goWfAJlufDuTEjf2vnBCyFEK/rsg0Un4ulky9NzjU/WBWOCG9fvu3N6P+76ZDs/xh3hvGEBJz6RUjDgXGM8+6J58P75MPM5GHWtUXsXQrTtx4cgc3fHntNvKMx+vs3dDz74IKGhodx+++0APPnkkyilWLt2LQUFBdTU1PDss88yd+7ck3rbyspKbrvtNmJjY7GysuLFF19k2rRp7Nmzh+uvv57q6mrq6+v54osvCAgI4NJLLyUtLY26ujoee+wxLrvssj902XAa99ABLh8bwuVjQ5otxnruUH8ivR1589fkkzuZZyTcuNIowXz3F3h/DuxfAXWy9qkQPcmCBQsaF7IA+Oyzz7j++uv56quv2LZtG2vWrOHee+9tcybGtrz22msA7N69m08++YRrr72WyspKFi5cyJ///Gd27NhBbGwsQUFB/PTTTwQEBLBz507i4uKYNWtWh1zbadtDb4vZpLh8bAjPfr+X1Pxygj0cyCmp4mBuGWPDPY5/sLMfXPstbP8Ifn4CPr4EnPxg+GUw/ArwGdA1FyFEb3GcnnRnGTlyJNnZ2WRkZJCTk4O7uzv+/v7cc889rF27FpPJRHp6OllZWfj5+bX7vOvWreOuu+4CYMCAAYSGhrJ//34mTJjAc889R1paGhdddBFRUVEMHTqU++67jwcffJDzzjuPKVOmdMi1ndY99LbMHGz8Iy7fkwnA49/EccX/NlJU3o6RLEpRNGABy2etoe6SRUaP/fdX4fVx8O4s44nT+hOMfxdCdKr58+ezdOlSPv30UxYsWMDixYvJyclh69at7NixA19fXyorK0/qnG316K+44gqWLVuGvb09M2fOZPXq1fTv35+tW7cydOhQHn74YZ5++umOuCxJ6K0J9nBgoL8LP8VlklFYwYr4LGrrNav3ZQFQW1fPwdyWS6dW1tTx1Ld7mPD8Kv70cRwr6scYQxzvTYCzn4GSI8YTp1/eDPXHGRophOhUCxYsYMmSJSxdupT58+dTVFSEj48P1tbWrFmzhpSUlJM+59SpU1m8eDEA+/fv5/Dhw0RHR5OcnExERAR33303F1xwAbt27SIjIwMHBweuuuoq7rvvPrZt29Yh1yUJvQ0zB/uy9XABr6xKRGuNq701K/YYCf2V1Umc/eKvpOY3n+jr9TVJvLf+ELMG+2FSsDezxNjh5AOT7oa7tsP0x4xe+srHuvqShBAWgwcPpqSkhMDAQPz9/bnyyiuJjY0lJiaGxYsXM2DAyZdHb7/9durq6hg6dCiXXXYZ77//Pra2tnz66acMGTKEESNGkJCQwDXXXMPu3bsZO3YsI0aM4LnnnuPRRx/tkOvqs/Oh/1F7jxQz++XfADh7kC8+zrZ8tT2d3x6YxrR//UJxZS33z4zmjmn9AMgorGD6v3/hnEF+vHL5SM58YQ0D/V1446rRzU+sNfz0EGxaCKOvMxK8o1cXX50Q3UfmQ2+/k50PXXrobRjg50yIh7H+6LUTwjhnsB/l1XX8eckOiitrCXC148ttaY11s38t30e9NtY4BYjydSYxu7TliZWCmX+D8XfAtkXwykhjfpiak6vXCSHEsSSht0EpxTUTQpncz4tJ/TyZEOGJs60V65JyGR/hwZ3ToziQU8aejGI2HMjjy+3p3DQ5nCB340Ogv68Th3LLqK5tpVZuMsOsv8HtGyF0krGoxqsxkPxLl16jEKJ9du/ezYgRI5p9jRs3rrvDakGGLR7HTVMiuGlKBAA2VoppA3xYtjODW8+IZESwG08si+PlVYlsSs4jwtuR286MbDy2v68ztfWag7llRPs5t/4G3v3hiiVwcC1891f4/Hq4YzM4eXfF5QnRbbTWzZ7/6OmGDh3Kjh07uvQ9T6UcLj30k3DbmZH8+awozujvjZuDDdOifVgZn4WttZkPrh+Ls511Y9t+Psb8D4nZJSc+cfhUuGwRVJXAjw90VvhC9Ah2dnbk5eWdUsI6XWitycvLw87O7qSOkx76SRjo78JAf5fG19dPCicpp5RXFowk2FJvbxDp7YRJwf6sVurorfEZCGc8CGuehSEXGwtWC9EHBQUFkZaWRk5OTneH0qPZ2dkRFBR0UsdIQv8DJkR6svreM1vdZ2dtJtTTkcSsdvTQG0z+C8R/Az/cDxFngG0bpRohejFra2vCw8O7O4w+SUounaifjxP7LQk9Ja+MmuPNsw5gtobzXoKSDPil6x+JFkL0bpLQO1F/XycO5ZXz0cYUznjhF656exMFra2I1FTwGGOmxo1vQNaerglUCNEntCuhK6VmKaX2KaWSlFIPtdHmTKXUDqXUHqXUrx0bZu/U39eZunrNo1/HMTTQle2HC7nw9fWkF1Yc/8AZT4KdK3x9G1SXH7+tEEJYnDChK6XMwGvAbGAQcLlSatAxbdyA14ELtNaDgUs6PtTeZ4CfcQN1XLgHn/1pAp/cMo70wgoWbTjBPBEOHjDvdTiyy0jqMu+LEKId2tNDHwskaa2TtdbVwBLg2JnfrwC+1FofBtBaZ3dsmL1TtJ8z7103hveuH4O9jZnRoR5E+zmzJ6OozWPWJGSzNSUfomfD2U9D/Nfw7V2QGWdMGyCEEG1oT0IPBFKbvE6zbGuqP+CulPpFKbVVKXVNaydSSt2ilIpVSsWeLkOWpg3wwcHm6GCiIQGu7E4vanUMbmlVLXd+vI1nv99rbJh4F4y7DXZ8DAsnwQfnQ21VV4UuhOhl2pPQW3uc69hsZAWMBuYAM4HHlFL9Wxyk9Vta6xitdYy39+n5NOTgQFcKy2taraN/tS2Nsuo69qQXU1VbZ8z7Mvt5uHe/UVc/9BusfKLrgxZC9ArtSehpQHCT10FARittftJal2mtc4G1wPCOCbFvGRJg1NXj0oubbddas2hjCjZWJqrr6tmT0WS/kzdMvgfG/gk2vQF7v+vKkIUQvUR7EvoWIEopFa6UsgEWAMuOafMNMEUpZaWUcgDGAXs7NtS+YaC/C2aTaqyjv7YmiXfWHWRtYi77s0q5yzId7/bDhS0PPucZ8B8B39wOBSc/Ab8Qom87YULXWtcCdwLLMZL0Z1rrPUqpW5VSt1ra7AV+AnYBm4G3tdZxnRd272VnbSbKx4nd6UXsySjiheX7eOa7eK57bzOu9tbcNCWCQDd7th0uaHmwlS1c8p5xc3TpDVB7gjHtQojTSrvGoWutf9Ba99daR2qtn7NsW6i1XtikzQta60Fa6yFa6/90Urx9wuAAV+LSi3hn3UEcbMy8dfVoJkR4cvdZUdjbmBkR4saO1nroAB4RcMF/IT2Wg0vu69K4hRA9mzwp2g2GBrqQW1rNNzsyuDQmmHMG+/HxzeO5cbIxv8WoEHfSCyvIKm5j0YvB81jvcSHhSR9Qu/7VLoxcCNGTyeRc3WBIoCsA9Vpz3cSwFvtHhrgBsP1wAe4ONmQWVzJ9gE+z6Xkfr7yKe+vSOXflI1CSDjkJRl396q/APbQrLkMI0cNIQu8GDTdGp0X7EObl2GL/4AAXbMwmnli2h6xiY9y5rZWJW6ZGcO850WQVV3Igv4o/cycTQt7FfePr4B4GZXlGbf2Gn4yJvoQQpxUpuXQDR1sr/nfNaJ6ZN7jV/bZWZkaGuFFQXsM9M/rz+a0TmNTPi1fXJJFVXMnmg/kA1GDFmhH/gTtj4e4dMNeorbPqqa67GCFEjyE99G4yfYDvcfe/duUo6us1Pi7GiiWec2xYnZDNsh0ZHM4vx97aTEVNHenFteAVZRw0+EI4+Bv8/l+IPhdCJ3b2ZQghehDpofdQXk62jckcIMLbieHBbny1PZ0th/KJCXPHy8mWjKJjnjg951lwCTKWsquv6+KohRDdSRJ6L3LhiADijxSTkFnCuHAPAt3sSCs4JqHbOBgPIGXuhq3vd0ucQojuIQm9FzlveABmkzG1zrgITwLc7MlobW71wRdC2BRY/Yxxo1QIcVqQhN6LeDnZMjXKC1srE8OCXC0JvbLlzI1Kwex/QnUZfHu3TLsrxGlCEnov89QFQ3j72hhsrcwEuNlTUVNHYXlNy4a+g+CsxyHhO9j2YdcHKoTocpLQe5kQTwemRBlTDwe6GTdN21zSbvwdEH4G/PSQrE8qxGlAEnovFuBmD9B6HR3AZIILFxrrky66CPIPdmF0QoiuJgm9FzthQgdwCTCmA6irgkXzIPFnqKvtmgCFEF1KEnov5ulog62Vqe2SSwOfgXDlUqgqgcUXw0uDIGNHl8QohOg6ktB7MaUUgZaRLicUFAN/3UvFRR9QWlFJ+YpnOz9AIUSXkoTeywW42ZNeWEF2cSUr47NaXXy6kZUtzx/sxztV07E/9DPkHei6QIUQnU4Sei8X4GbH/qwSZrz4Kzd/GMtPcZlttt2aks+HG1P4qPZs6jDDpoVtthVC9D6S0Hu5EA8HyqvriPJ1JtrXmae/i6e8uhatNXmlVY3tqmvrefCL3QS42jMtZgjf1U9Eb18MFYXdF7wQokPJbIu93NUTwhjg58K0AT5sP1zA/IUbePSrONILK9hyKJ+lt01kVIg7P+3JJCm7lLeuHk1tvebVrbOYZ1oLW96GqbKUnRB9gfTQezlXe2tmDPLFbFLEhHkwf3QQX25PJzG7FDtrMx/+fgiAz2NTCXSzZ8ZAX2LC3InXYaR4TYX1r0B5fvdehBCiQ0hC72MeP38Qz180lF/uP5P5o4P4YXcmu9OKWJeUy/zRQZhMCh9nO8I8HXjP7mqoKoZ1L3V32EKIDiAJvY9xsbNmwdgQXOysuWp8KNV19dz60Va0hvmjgxrbjQnz4JsMN/Swy2DzW1CU3o1RCyE6giT0Pqy/rzNjwzxIL6xgUj9Pgj0cGveNCfegoLyGL1yvobaunorFV0JlUTdGK4T4oySh93FXTQgF4NKY4Gbbx4Z5AHDfykJuq7oT65zdsOhCGfUiRC8mo1z6uPOH+ePlaMP4CM9m28O8HFl41Shc7W14/Rcvns614+kjL6CXXs/FRfcwqb8v954T3U1RCyFOhfTQ+zilFBP7eWGyrHTU1Kwh/kyI9GRCpCcfFgyhdMbzqAOrmZr5Hu+sO0hRRSvzrAsheixJ6KKx/LLOeQ77/M7nbvNXxNRu45PNh7s5MiHEyZCELhga5IqNlYktKQU8w40cNgfzkv07fLZuLzV19d0dnhCinSShC2ytzIwIdmNNQjYbDlewftDjeNblckXFR3y/60h3hyeEaKd2JXSl1Cyl1D6lVJJS6qFW9p+plCpSSu2wfD3e8aGKzjQu3IPk3DLq6jUDxpyFHn0D11st55sff6CkUmrpQvQGJ0zoSikz8BowGxgEXK6UGtRK09+01iMsX093cJyik42x1NHdHawZEeyOmvEE9faePFX1D/775S/dG5wQol3a00MfCyRprZO11tXAEmBu54YlutqoUHfMJsWZ0T6YTQrs3bC+6lN8rcq5POEO1m3f1d0hCiFOoD0JPRBIbfI6zbLtWBOUUjuVUj8qpQa3diKl1C1KqVilVGxOTs4phCs6i5OtFe9eN4YHZjUZex44GnX1l/iaivD+4RaolxukQvRk7UnoLQcww7HL4mwDQrXWw4H/Al+3diKt9Vta6xitdYy3t/dJBSo63xn9vfF3tW+2zSZsPD8G/5Xomr3o3Z91U2RCiPZoT0JPA5o+Nx4EZDRtoLUu1lqXWr7/AbBWSnl1WJSiW1UNvowd9RHUrXgCqkq7OxwhRBvak9C3AFFKqXCllA2wAFjWtIFSyk8ppSzfj7WcN6+jgxXdY1CgG0/XXINVWSase7G7wxFCtOGECV1rXQvcCSwH9gKfaa33KKVuVUrdamk2H4hTSu0EXgEW6OOuVix6k2hfZ3bQn31eZ8Omt6CqpLtDEkK0ol2Tc1nKKD8cs21hk+9fBV7t2NBET2FvYybcy5GlNvN4pHol7FwCY2/u7rCEEMeQJ0VFuwwKcOWH/AAIHA2b3jRGvNRWyRzqQvQgktBFuwzydyG9sILyETdBXiL8+g94NQbemAQ1lcc9NiGzmAteXUdheXUXRSvE6UkSumiXQQEuAOx2mwZOvvDr85SWV0JRKmxfdNxj1yXmsiutiNhDBV0RqhCnLUnool0G+RsJfU9WJZz3EnraI5zHy8TW96f2t5egtu3e94GcMgDijxR3SaxCnK4koYt28Xa2xdvZ1kjKA+awN+pWDhVrXq2dh1VJOuz6tM1jD+YaY9fjMyShC9GZJKGLdhsR7Mav+3OorKnj571ZKAWJzuNJto6C9S+3edzBXOmhC9EVJKGLdrthUjg5JVV8uiWVVXuzGB7kxtyRgSyqmGjcKC1Ka3FMaVUtWcVVuNpbczi/nGKZileITiMJXbTb+AgPxoS589/VSexMK+LsQb6cNdCXLXVRRoPUTS2OOWTpnc8a7AdAwhF5KEmIziIJXbSbUoo7p0eRW1oFwFkDfRgR7EaOfT+qlB2kbm5xTLIloc8Z5g/AXim7CNFpJKGLkzI1yovhwW6EeDgQ7euM2aSYOjCAnfWR1KVsbNE+OacUpWBsuAeejjZyY1SITtSuR/+FaKCU4p1rY6isqcMyHxvXTAjj1539iMn8DqrLwMaxsf3B3DIC3eyxszYzKMBFbowK0Ymkhy5OmpeTLUHuDo2vhwa5UuM/BhN1VKbEklVcyZqEbMBI6OFeRoIf5O/CvqwSaupkoQwhOoMkdNEhzpwxB4Cfly/jg5cewv/j6Wxd/QXJOWVEejsBMNDfheraepItDxoJITqWlFxEhxgZHUGaVQgTcj7lPFVCmckex7U3cG/dTEyezwMQ6mn06tMKyon2c+7OcIXok6SHLjqMS9QkPFUJdYMuJPHqLSyqm8H1VssZXb0FoHF5u8zi40/mJYQ4NZLQRYdxmXE/nPMc5ovfZkRkMMmjHyNDexCV/AEAXk42mBRkFklCF6IzSEIXHcczEibeCWajkvd/5w9Djb8N29T1cGQnVmYTPs52ktCF6CSS0EWnsTab8D/zFrBxgg2vAeDraiclFyE6iSR00bns3WDk1RD3BRQfwd+leQ89p6Sq+2IToo+RhC4637hboL4Wtn2An+vRhH44r5zxf1/F8j2Z3RygEH2DJHTR+TwiIPIs2PoB/s5WlFTVUlZVS0JyMh+an2VrbMspA4QQJ08SuugaY26EkgxGlBvJO7O4Eofdi5lk3oPtoVXU1etuDlCI3k8SuugaUTPBJZDotM8AyCwoY2DGFwAE1RxmR6qsNyrEHyUJXXQNsxWMvg63I+uIUQmQtArP2iyqsKW/KY1Ve7O7O0Ihej1J6KLrjLmJeo9I3rN5gX57XiZHu7LXZzbR5gxW783q7uiE6PUkoYuu4+CB6dpvKVQu+JYl8GndmeA3FAddTnHWITIKK7o7QiF6NUnoomu5BvKIy99YVHcO79XOwiVkGABRpnSWbD7czcEJ0btJQhddzuQewmM115GvXPHvNxKACwOLWfhrMknZsuaoEKdKErrocn4udgAEuztg7+YNjj7M8i3EwdbMw1/upl6GMApxStqV0JVSs5RS+5RSSUqph47TboxSqk4pNb/jQhR9jZ+rkdD7+xoLX+AzALuC/Txy7kC2HCrg2vc2s+vHtyk8uE2SuxAn4YQLXCilzMBrwNlAGrBFKbVMax3fSrt/AMs7I1DRdzT00Pv5WBa58B4AOz5m/qhAsoorKVj/LsNSX6d2o4n36mfhNOsJLps0oBsjFqJ3aE8PfSyQpLVO1lpXA0uAua20uwv4ApABxeK4WvTQvQdAdSmqOI07B1XyqHqXAp/xJAVdxI3mH/DY+PdujFaI3qM9S9AFAqlNXqcB45o2UEoFAhcC04ExbZ1IKXULcAtASEjIycYq+oiYMA8ujQnizGgfY4PPQOO/X9wE+ckoe3fcr/kIdydvdv47m+Ela6G+Hkxyy0eI42nPb4hqZduxhc3/AA9qreuOdyKt9Vta6xitdYy3t3c7QxR9jZOtFf+cPxwPRxtjg98w8B0ClcUQMBIWfAxOxv8fBcEz8CGfggObuzFiIXqH9vTQ04DgJq+DgIxj2sQAS5RSAF7AuUqpWq311x0RpOjjbJ3gtvWt7nIYci61e56keMc3uEeN7+LAhOhd2tND3wJEKaXClVI2wAJgWdMGWutwrXWY1joMWArcLslcdITosDBidTROh5rfa3/mu3j+8VNCi/YZhRVsOywTfYnT0wkTuta6FrgTY/TKXuAzrfUepdStSqlbOztAcXpzdbBms814PMsOQP5BALTWfLEtjY82pFBTV9+s/V8/28EV/9tIcWVNd4QrRLdq110mrfUPWuv+WutIrfVzlm0LtdYLW2l7ndZ6aUcHKk5fmf7TjW/2/QBAWkEFheU1lFTVsjXlaG98T0YRG5Pzqayp55vt6d0RqhDdSoYNiB7PN3Qge+tDqIv7CoC49KLGfWv2HR0l++66QzjYmInycWLxpsNofYKHkuqkFy/6FknooscbHODCN3UTMadvgfyD7E4vwsqkiAl1Z02CkdCzSyr5dmcGl4wO4rpJYSRklrAzrajtk/76T/hHOOQd6KKrEKLzSUIXPd7gQBe+rZtgvIhbyu70Ivr7OjNriB/n5C6iZNmDvL46iZr6eq6bFM4FwwNwsDHztx/2cvU7m7j4jd+PLnGnNaz5G6x5DqpLYO+33XdhQnQwSeiix/NzsaPSMZAku2HoXZ+zO62QoYGunGfawH3Wn+O8bSHuW/7N5WNDCPdyxNnOmnkjA9l8MJ9daUVsTSlgf5ZlFsd9P8Kv/4ARVxpj3xNXdO/FCdGBJKGLHk8pxYUjA3m/NAaVuw//ygNMdMvH99cHiDNF83ntVP5s9SXPhu5oPOaxOYP4+a9TWXbnJICjQxmT14C1I5z/CvSfCYc3QoUMcxR9gyR00StcPzmcn+rHUYuZT22e4YJ181BmGwrnvEXdnP+gw6diWnYnfPknSN+K/a4P6Zf5IyEeDng62rAtpdA4UVosBI4y1jiNmgm6Dg6s7tZrE6KjtOdJUSG6XaCbPZOGRfPi7osZYkrh7GnTsR4yj8k+llkYxyyFtf+CdS/CriWWoxSq3wxGhriz/XAB1FRC5m6YcIexOygG7D1g/woYcnG3XJcQHUkSuug1bp4SwXk75jHQx4Vzp09pvtPKFqY/YiTmzN3GRF5Lb4DkXxgVOoyf92ZRfGgbLvU1RiIHMJmh3wxIWgn1dcZrIXoxSeii1xgS6MrlY0OI9HZsu5HPAOOrrhbsXOHAKkYNPQOAzPjfcAEIjDnavv9M2P0ZpKyH8KmdGr8QnU1q6KJX+ftFQ7lpSsSJG5qtIOJMSFrNsEAXzCZF3eFYcAkCF/+j7aLPBQcvWP9K+4M4sgvKck86diE6myR00XdFngUlGTgUHWCgvzOehbsgaHSzJhXY8pvnfEhayYKn/0dCZvHxz1lXC+/PgZ+f7Ly4hThFktBF3xVpmQPmwCom+4FPXSZ1Ac0T+or4TO5IHE059lxR8wVbDp1gCGPuPqgqNoY7CtHDSEIXfZdbMHj1h/hlzK81ngiNN/Vv1mTTwXy0rSt2E25mjmkjITtfhvRtbZ+zYV9eIpTnd1bkQpwSSeiib+s3A1I30m/fm6Rpb5akeTXbvflgPjFh7pgm/5l460FMOfIu/G8a7P2u9fOlbz36fdqWTgxciJMnCV30bVPvh/nvwp2xvDjoc5bF51NVa6yUmFtaRVJ2KWPDPcHRi4Xhr3Kh44fg5Nc4lr2+XvPwl7vYkVponC9jGwSNAWWG1JNcFq+iEDJ2dNilCXEsSeiib3PwMMame0Uxd2QQJZW1/LIvB4AtB42SydhwDwDCvRyJK7CibsAcSFoF1eUkZpfyyeZU3v4t2XgwKWsPhE0BvyGQdpIJfeVj8O4smbZXdBpJ6OK0MSnSE09HG5btNJbE3XQwHztrE0MDXQEjodfVa7IDZkBNORxY3TgHzC/7cqhO3wH1tcbUAUFjjXp6/XHXRT+qthriv4HaCpmyV3QaSejitGFlNjFnmD8/x2dxIKeUzQfzGRXijo2V8WsQbnlgaa/tMLBzg4TvjCkDgNKqWlJ2WxayDhwNwWOhuhSy49v35gdWQ6VlfvaclmuhCtERJKGL08p1E8NwsrXiotd/Z29mMePCPRv3hXsaCT05vxqiZ8O+H9mZksvESE/src2UJW8y6usuAUYdHdpfR9/zpfHkKgpy9nXwVQlhkIQuTisR3k58dfskvJ1t0RrGRXg07nN3tMHNwZqDuWUw8HyoLMQ3bxMTIz2Z2t8Lt4I4dOBI0gsrKHcMAucAWP0MrHwCSnPaftOaCkj4HgbNBfdQyNnbBVcqTkeS0MVpJ8TTgS9um8ibV49mXLhHs33hXo5GQo+cTpW9Lw9bfcKoICeuc9tFGOkszg5n8j9W8/KqJLhiCYRNht9fgWV3tf2GiSuM8syQi8F7gPTQRaeRhC5OS6721swc7IdSqtn2xoRubc9Pofcz0HSYmP0vMS7+GXbXh/O3nIk42VixL6sE/IfDZR9BzA1w6DdjWoDWJK4Ae3cInQze0ZCb2HZbIf4ASehCNBHh5ciRokoqquv4onw4a60nYRP7JqbqMqwufouV981gUj8vUvPLjx4UOsnogR/Z2fpJs+LBb5gxYZj3QKivgfzkrrkgcVqRhC5EE+FeTgB8tT2d7YcL+K3fg0aZZPbzDBw+lkA3e4I97EkrqEBry8LTocYydxz6reUJ6+uNEovPIOO1d7TxXxnpIjqBzIcuRBORPsZIl//7ajcAY4ZEw+BNzdoEuTtQVVtPTmkVPs524OwLnlHGnOqT/9L8hEWHoabMmKMdjLllQOroolNIQheiiWhfZ167YhQu9lYMDnDFw9GmRZtgD3sAUvMrjIQOEDYJ4r5sufJRtmVES0MP3dYJ3EKkhy46hZRchGhCKcWcYf5MifJuNZkDBLs7AJBW0LSOPtmYVjdzV+Omt39L5sufVhovvAccbes9QBK66BSS0IU4SUGWhN7sxmhYQx19feOmJVtSMeXupdDGD+xcWLU3i/fXH7SMdNmPrquhvl53Zeiij5OELsRJsrcx4+VkQ1pBBQApeWVk4QEeEXDwVwCyiytJyi5lkFUG2yr8uObdzdz4QSxPfhtPpecgqKtm/cb1jHh6BaVVxwxhLD4C6182JgMT4iS0K6ErpWYppfYppZKUUg+1sn+uUmqXUmqHUipWKTW540MVoucIcncgtaAcrTXXvLuZB5buMtYnPbAGyvLYkJyHmTr6qQwKnPqxLjGHyf2MudgP2xg3RnP3b6a4spaDOWVHT3xoHbw5FVY+Dnu/7Y5LE73YCRO6UsoMvAbMBgYBlyulBh3TbBUwXGs9ArgBeLuD4xSiRwn2cCA1v4IDOaWk5JWzNaWAumELjDHmcUv5PSmPwXa5mOqrOXf6NH7+6xk8eYHxaxNf4wPWjjjkxgGQ2lCLT4uFDy4AOxewcYJUWeau06VvhYztJ39cTYUxxbLuWSWz9vTQxwJJWutkrXU1sASY27SB1rpUNw7KxRHoWVcpRAcLdrcno7CCn/dmA8ZsjPsJBb+hsONjNiTnca6PMVOjfeAQIrydCPFwxGxSJOVUgP9w/MqNG6OHG2rxW98Dawe4aZUx+ZesW9q5airg4wXw0fyjM2G21/JH4KOLYPuizontFLUnoQcCqU1ep1m2NaOUulAplQB8j9FLb0EpdYulJBObk3OcyYyE6OGCPRyordd8uiUVT8tomK0pBTD8CjiyA9uC/UxwPAKoxoeJbKxMhHo4cCCnlCrvoUTVH8RMnXFztaYS4pcZk4LZu0HIBGMxjYrC5m98oh5h3oGWx7RHQQpserPH9Tg73J6vj64ateNjKMuG8lz47cX2n+PILuPD18oOlj9q3PPoIdqT0FUr21r8q2utv9JaDwDmAc+0diKt9Vta6xitdYy3t/dJBSpETxLkboxFP5hbxvzRQXg52bItpQCGXkK9suI9m38y7ODbEDASrO0bj4v0ceJATikZjtHYq2r6qXRSCypg/0/GsMdhlxoNQ8YD2ijDNChMhX9Hw9d3QFVJ84ASvoe3Z8B/R8GXN5/8Ba15Dn58oO9OSaA1/PIP+Pxa+PAC4/mA9S9DYAwMvxw2vg4Fh9p3nh8fAHsPuP5HqKuCH+47+kGYnwyvjIKUDZ16OW1pT0JPA4KbvA4CMtpqrLVeC0QqpbzaaiNEb9cwFh3gzGgfRoe6sfVwATh5s9VxKk6qEqbeB1d+3uy4SG8nDuaWsbs+AoDZnplGD33XZ8Zc6+FTjYZBMWhlJnvPL0eHNq58DCoKYOfHsHDy0YeWClPhs2ugPB8iz4LElZB/sP0XU1ForKYEkLrpuE07hdadsyxffT2sewmW3W0k8l/+BoMvBLMNvH02FKbAlL/CWY8ba8T+8MCJV6Da9Skc3gAznjBWrjrzYUj4zpiADYwPifwD8P29rU/AVnwEfn/VuPndCdqT0LcAUUqpcKWUDbAAWNa0gVKqn7JMW6eUGgXYAHkdHawQPUWAmz1KgZOtFTFh7owOdSclr5xf9+ewIO8G3hizHDX9UXBs3q/p5+NETZ1mWao9ZdqWyQ5plBbkoBNXwND5R58ytXGkwGUAydt+ZlVCNhz8DfZ8BVPuM3qG1WXw9W1G0trwqnHMNd/A3FdBmWDbB+2/mN2fQ20lmKxPLaEfWAM/P2V8qJzKyJyVj8FrY1v+1fFHbX4Tfn7S+OvlwC8w/na4+F24bDHUVYNXNPSfbSxYMuNJSFxuJP/6+tbPV54Py//PuL8x4ipj24Q7wCPSGJVUlA47PjGeCs7eY5RlwPiQSPgePpwHLw6EFY8YH7qd4ISP/muta5VSdwLLATPwrtZ6j1LqVsv+hcDFwDVKqRqgArisyU1SIfocGysT4Z6ODApwwdpsYnSoOwB/XrIdVwc7bp8e3epxkZZl7tYmFXDIPpLIil28aEpA1dfAsMsa2+WWVvFTURgXq5V8nbgF0p4F1xCYdLdRwpn5N6O0sv4l2PoBDL0U3Cx/SEfPhm2L4Mz/A6vWn3ZtZtuHxmyQTj5w+CQT+sG1sGgemKyMKYLjv4GznoDJ94BqrVp7DK1h91IoOWIk3zn/Prn3b0tmnJFk+8+Cy5c0jyVkHNz0M9g6g8nSpx1/K5Tnwdp/Gsn+zIfAM7L5OVc8atw8Pf+Vo8eZreHsp+DTq4ybpPU1xpTK390Dq581bmwf3gDF6eASCGc8AEMvAa+ojrnOY7RrLhet9Q/AD8dsW9jk+38A/+jY0ITo2T66aRyOtsav0OAAV2zMJgrLa3hm7mBc7a1bPSbSx5jNsbqunlyXwQzO/5yxJmuSJzxPhP+wxnZPLtsDtf25yup7Lt9+pdF7XrD4aD1+6CUQ+y6sehpQzScFi7neKAMkfGssqtGasjw4sMpIUJm74Nx/GaWXpGeNso69+4l/AHU1RpnCLQRu32iULb65A1Y9BboOpt5/4nMc2WEkc6/+sOVtoyQS9gcfY6mtMj7s7Nzggldb/2Bp8rNuNO3/AG2UaXZ/ZkzRUF0Ouh6c/SA9FqbcC77HjNoecB4EjzeGmQ6aZ3wQzP4H/G+6kcwDR8HM52DA+cYUyp1IJucS4hQFuB292WlnbWZUqBt5pdVcPjakzWNc7KzxcbYlu6SKnNA5VNilccnBOVzndT4Rljaxh/L5btcRHpo2j9937iCOftxyx0PNyzdKwbkvGA8hRZ97dFpegIjp4B5uJPvQSUYyaqq2GhbNhUxjRkmsHY1yT8Pr1C3Q/5wT/wC2vGMsp3fZYrAx/vLg4rehvhbW/guGLTj6V0Nb9v1klIiu+hI+OB++ug2u+xbcw078/m357UVj8e4rPgOnkxh8oRRMfxRibjRKVkd2Gb14paAoDaLOaf1DSimY9Xejlz71PmObz0B4KLXTE/ixJKEL0UHeuHI0SoGV+fi3piK9ncguqcKl3wRMcy5gz2M/NZsX5ottaTjYmLlm2hBeqH6OJZtTucnes+UNL7+hcP1PLUsDJhNc9D/4cK5Rt73ue3A8uhg2a54zkveFb4LvEGPxant3CBxt9LJTN504oSd8b5wncjoMmHN0u1JwzrPGqJ1VTxkJ/nj2/QBBY43EP/9dWHQhvDMTrv4SfAcf/9jWZCfAb/82/oLpP/Pkjwdw8TdKLicjcBT8Nb75ti5O5iBzuQjRYYxFpk9cs+5nKbtE+Tpja2XG38WuMaFX1dbx/a4jzBrsh4ONFZHeTlTU1HGkuI15XULGtbjxCkDwGLj8E2MY3UuD4c0z4Iub4ccHjZEYo66F4QvAb8jRXrSNo1GKOLwREn6A7/4KZbnNz1tdDkuuhCVXgGswnPdSy5KGWzBMuNO42Zq6ue0fRFGaUe6Jnm28DhwFN1h67B+cb9z4bY+qUuNpz12fw1d/MqYonvn39h3bx0gPXYguds5gX1ILygnxMIY+Bnk4ND7+vyYhh+LKWuaONJ7da0j+B7JLCWxS4mmXiDOM3nn818ZDSqkboTjD6NnP/FvrxwSPg00LIcUyrO7wBrhm2dHSxY8PGL3zs56AiXcZNwVbM/ke2LEYvrgRblzZsuwDRi8ejiZ0MEoV89+B92YbDwGNvLLt60v+Bb79CxQ0GaJpsoaL3jq5UksfIgldiC42JcqbKVFHE06IhwPrEo2e8Dc70vFysmFSpFEiifS2JPScUqb2P4UkFTzG+GpQXweoo6M0jjX0UkjfBqOvBWd/oy78/rlGGaWiwHjUfcp9xvjt47F1ggUfw/vnwUcXGzdqY98H91C4+B1jDdbf/2us9NSwilPjD2SCsX37orYT+pa3jRuyXlEw/THjHF5RxoyXVrbt/en0OZLQhehmwe4OZJVU8u3ODFYlZHPF2JDGOryXkw2u9tYkZZcCkFNShYejDWZTO4YEtqbpakqtCRoNNzUZI33lUlh6A3zc8ATrBONhmvYIHAWXLTKO/f5eY9x3wnfw2dVQWQwlmXDtdy1LNkrByKvg5ycgZz94H5Pw474wzhc106jR27m0L57TgNTQhehm0X5OaA13fbKd6tp65o8OatynlCLS25EDOaUkZpUw6fnVfB57dGqlP7pAxo7UQv61fB9tPjYSNgnuiYNLPzTq7vPfPbmbff3OMh6EumE53LEJzn/ZeKoydSPMe6P5Xw9NDb/cuEF77ORXVSXGxFj+w42/ACSZNyM9dCG62TmD/PjpL1PQGlzsrVvUyiO9nVizL4d/r9hPdV09mw7ms2BsCHX1mjP/tQYvJ1uemTuEIYGujcek5JVhY2XC3/X4dffPY1NZvOkw80YGNtbrWzBbw6C5xtepCB579PvR1xnjw+uqYchFbR/j7Gs8FLTzE5j2CFhb1m5d+4Ixbv3SD7tlFElPJz10IbqZyaQY4OfCQH+XVm989vNxMp4c3ZOJlUmxM60QgH2ZJaTmVxCXXsQFr67jvfXGzcGCsmoufP137vt8Z+M5vt2ZYSx/d4yDucZIkjUJ2R1+XbV19a3/BTF43tFJyI5n3J+gLAc2vma8zoqHDa/DiCubf0iIRpLQhejhGm6MujtYc+PkcJJzyiiprGFrSj4AX90+iekDfHj2+71sOZTPcz/sJb+smthDBVTVGpNNvbwqkf+sSmxRWmlI6KsSsjo87nmvr+eFFftO/QQRZ0D0HFj7b2OUzpIrjPHyM57quCD7GEnoQvRwgwJcMJsUd06PYoJl9Mvu9CJiUwrwdbFlcIALL102giB3e275MJalW9MYGuhKVW09u9OKGtc3LSyvIb2wovG85dW1HCmqxNHGzJZDBRRV1JBVXMmrqxNZGZ9FXmnVKcdcVlVLXHpx4+idUzbzWWN+lP9NN+ZDWbD4tB2S2B6S0IXo4QLc7Fn7wDRumBTGsCA3AHalFRF7qICYUA+UUjjbWfPq5aMoq6ojxMOBN68eDcCmg/n8fuDoxKdx6cWN3x/KNca+XzbGqMevTsji1o+28q8V+7n5w1im/nMNyTmlLeJp6PUfzwHLcQmZxe1q3yaPCGO8e22lcUNVSi3HJQldiF4g0M0epRQejjYEe9izYk8m6YUVjbM8AgwNcuWzWyew+KZxBLjZ09/Xic0H81mflIuLnRVmk2JPxtGl1hrKLReNCsTD0YbHvt7D9sOFvHTZcD6+eRxVtfV8svlwszgO5JQy6umVrdbjm0rMMhJ6TZ1mf2bLD4WTkTj4zzwR/D6Vgy87cePTnCR0IXqZYYFubDtcCMCYMI9m+0YEuxFseQJ1bLgHW1MKWJ+Uy8RIL6J8nIhLb5rQjUQb4e3ImdHelFbVctX4EC4cGcTESC9mDPTli23pzXrYy3ZkUFZdxzPf72VjcttLHiQ16dnvbvKep+LXxDw+SLRp7PWLtklCF6KXGRZkDE90sDEz0N+5zXZjwz0praolo6iSSf08GRzgSlzG0ZJLcm4Z/q52ONhYcd3EMC4fG8yjc45ODbtgbDD5ZdWsjD96w/SnuEyGBbkS6unAnR9v47+rEnl//UEKy6ubvXdiVilRPk642luzO73wD11vTolRyz9S2MZ8NqKRJHQhepmGOvqIYLfjzuw4tknvfWI/L4YEupBTUkW2ZaKvg7llhHs5Np7z7xcNw8766JOkU6K8CXSzZ8lm40Gm5JxS9mWVMG9EIG9dPRork4l/r9zPk9/G88nmpuvIQ1J2Cf19nRkS6PKHe+jZloSeUVRxgpZCEroQvczQIFdsrUxMjPQ8bjs/VztCPR3wdbElwsux8cGjOEsdvWlCb43ZpLg0Jph1SblsTSngx7hMAGYN8aOfjzMb/+8sEp+bjZeTbWP5BqCypo7D+eVE+jgxNNCNfZklf+jGaEMPvekIHdE6edRKiF7GydaKFfdMxc/V7oRtH549gNp6jVKKgf4uKGWMdBkZ7E5hec1xEzrA1RNC+XJ7Gte9uxk3R2uGB7s1W9jD2mwi3MuBQ3lH53M/mFtGvYYoHydMSlFTp9mXWYKDjRk7azNBTRbYbo/sEuMvCim5nJj00IXohUI9HbG1OsFEW8CsIf6cNywAMD4Iwr0ciUsvItkywiXC+/gJ3cPRho9vHo+rgzWp+RWcO6TlNLihno6k5B2duzzRMpFYlK8TQy1/FTz3/V5m/ue3Zk+vtldDDz2jC3voheXVvfImrCR0IU4jI4Pd+WVfDi+vSgQg3KuN+VuaCHSz55Obx3PNhFAuiWm5pFyYpwNZxVWUV9cCkJRdiklBuJcjwR72uNpbs+lgPs52VuxOKzqpCcWqa+spKK8B4EhR1/XQn/luL1f+7yQXzO4BpOQixGnk4XMHUFZV2zgvTJB7+xbNCPZw4Om5Q1rdF+pp9PJT8soZ6O9CUnZJs78gnp47mHqtqa6t58EvdpOSX37CUk+DHMvTql5ONmQWV1JXr0996uB20lqzNjGHnJIqaurqsT7BkoI9iSR0IU4jXk62LLx6NMv3ZFJUXtMhyaohOafklVkSemmzmRvnjjBWX2oYA78no4hwL0d+T8olq6SSC0cGtTypRUO5ZXiQG6sSsskuqTzhDJJ/VGJ2aeP75pdV4+ty4nsVPUXv+egRQnSYmYP9uHRMy/LJqQjxNG5yHsorp6SyhgM5ZQzwazk+PsrXCSuTYo9lLPyz3+/l4S93N5ZqGiTnlLJoYwpA4xDL4cFuQNfU0dcnHZ1/piGx9xaS0IUQf4iLnTWejjak5JWxMTmfunrNxMiWC1fbWpmJ8nVmT0YxmUWVxB8pprKmnjUJOc3a/efnRB77Oo680qrGksvRhN75dfT1SXk0VHVy/sAEZd1BEroQ4g8L9XTgUG456xJzsLc2MyrUrdV2gwNciM8oapyu187axPe7Mxr3V9XWsdoyN3tCZgnZxVUoBcMso2U6u4deW1fPpuS8xg+kXOmhCyFON2GejhzKK+O3pFzGRXi0OaRySIALuaXVfLollSB3e+aPDmJ1QnZj2WVdYi6lVcb38RnFZJdU4eFgg7ujDc62Vp0+0mV3ehElVbXMHWEM9ZQeuhDitBPq6ciRokqSc8qY3K9luaXBYEtPe1daEdMH+DBnaACVNfWNvfIf4zJxtrPCy8mWvUeKySmpwtvZFgB/N7tOf1q0oX4+fYAPjjZmckuqT3BEzyIJXQjxh4V5HX36c0pU2wtQNDytCkbSHBvugZeTLV9ZZnVcGZ/F2QN9GRLoQvyRYnJKKhsTeoCbPUdamc8ls6iSmGd/blzB6VQVVdTw4YYURoW44elki5ezrfTQhRCnn4ax6D7OtvT3bfthJSdbK8I8HbG3NjM+whOzSXFJTBCrErI5+8W1FFXUMGuIHwP9XTiQU0p6YSU+zsawQX9X+1Zviq5KyCK3tIrNBwvafN8vt6UR32SmydY8/+NeckurePKCwQB4O9n2zRq6UmqWUmqfUipJKfVQK/uvVErtsnz9rpQa3vGhCiF6qnBLQp8c5YVSx3/w58pxIdwyNaJxZsf7z4nmxUuHU1lTh5uDNVP7ezPQ34WaOk1u6dGSS6CbHfll1VTWNJ/o69d9xiiZphOENZVVXMm9n+/kHz8ltBnThgN5fLI5lZumRDTOZunlZEtuO3rox67T2p1O+GCRUsoMvAacDaQBW5RSy7TW8U2aHQTO0FoXKKVmA28B4zojYCFEz+PqYM3/nTuAM/r7nLDtTVMimr02mRQXjQpi9hB/SqpqsLM2M6jJPO8+TUouANtSCphoqdNX19Y3LrHXsALTsb7dmYHW8PuBXIrKa3B1sG7R5vkf9xLsYc89M/o3bvNytmHjweMn9K0p+Vz33hY+v3UCA/xcjtu2vl6jFCf8wPsj2tNDHwskaa2TtdbVwBJgbtMGWuvftdYNf+9sBNp+9EsI0SfdMjWS6FYeKGovextzY3klzNMRWysjPfm4GAl9+gAfQjwcuOPjbY1rnW5NKaC0qhYfZ9s2E/qynRm4O1hTU6f5eW9Wi/1x6UXsTCvihknh2NscHZ3j7WRHYXkN1bX1bcb83a4jlFTW8vLPice9tvLqWsb+bRWfbkk9brs/qj0JPRBoGkWaZVtbbgR+bG2HUuoWpVSsUio2JyentSZCCIGV2dT44eDtZCR0NwcbPrxhLCaluObdzWQUVvDr/hysTIrLxgSTW1pNUUVNs/Mk55SyK62I286MxN/VrnFO96aWbDmMrZWJC0c2T2tezjYA5JW13Utfuz8Hs0nxY1wmCZlt1+h/S8wlt7SKb3ZktNmmI7Qnobf290GrRSOl1DSMhP5ga/u11m9prWO01jHe3m3fCRdCiIGWEoZPk7lUwrwcee/6MRSV13DJwg38GHeE0aHujdP0Hjqml75sZwZKwQXDA5k1xI+1iTmN49zB6Dl/vT2DOUP9cXOwaXZswwdJW0MX0wrKOZBTxu1nRuJka8W/V+znww2HuOrtTS2m3v3ZsozflkP5FFfWtHa6DtGehJ4GNJ30IQho8TGjlBoGvA3M1Vq3vXqsEEK0w6QoLzwcbfA/ZiGPYUFufHzzeMqra0nJK+eMaO/Ged2bll201izbkcG4cA/8XO2YPcSf6tqjY97BqK+XVtVyxbiQFu/vZandH3tjtGH637X7jTHrFwwP4PpJYayMz+Lxb/aw/kAu/2lSgqmr16xOyCbU04Haes36xFw6S3sS+hYgSikVrpSyARYAy5o2UEqFAF8CV2ut93d8mEKI0835w/zZ+uiMZuucNhga5Mqnf5rAnGH+XDQyiGAPB0yKxoU7wBi5kpxbxsWjjFt6o0Pd8Xe145nv4lmflMvK+Cz++dM++vs6MTrUvcV7NPTQGybo2picx5Vvb2T40yvYnVbE2v05BLja0c/HiVumRnD39H58cdtEbpkSwfe7Mhr/WtiRWkBeWTX3zOiPs50Va/Zlt3ivjnLCUS5a61ql1J3AcsAMvKu13qOUutWyfyHwOOAJvG65g1urtY7ptKiFEH3eiUaD9Pd15rUrRjW+DnJ3aNZDf3f9ITwcbTh/uPEYv9mkeO/6Mdz58XaufNtYvGKgvwuvLBjR6nt5NST00io+2pjCo1/H4eVki4ONmRs/2EJ5dR3nDfNHKYWznTV/PScagGB3e977/RBv/ZbM3y4cysr4bKxMiukDfVi515s1+3Kor9eYOmFe93bNh661/gH44ZhtC5t8fxNwU8eGJoQQ7Rfu5dg4Fv1wXjmrErK448x+zXr4A/xcWHbnJP61fD8u9lbcfmY/bKxaL1TY25hxsrUip6SKL7amMTzYjU9vGc/h/HIufv13Sqtqmdq/5b1AHxc75o8OYmlsGgP9nPlh9xHGR3jiYmfN9Ggfvt91hPgjxY2LdnckeVJUCNEnhHs5cjCnDK01H2w4hFkprhof2qKdg40Vj58/iL/M6N9mMm/g7WzLyvgsknPLuHp8KHbWZvr7OvPmNaM5d6hfqwkd4E9TI3Cys+Kxb/ZwOL+c2UONtVjPiDbar0nonLKLrFgkhOgTwr0cKauu45d9OXy6JZXZQ/3xc/1jqw15Odmw5VABznZWzBnq37h9YqRXq3O+Nwj1dGTDw9MpLK+hsqaOYHcHy/ls+fNZUa3W7DuCJHQhRJ/QsBTeDR9sIcDVnnvP7n+CI06soY4+b0Rgs4eO2sPWyoyvS8tj7umAuNoiCV0I0SdE+TphUkad/L3rx3TIWqAN88gsGNsxy/V1NknoQog+wd/VnmV3TibC2xEHm45JbZeMDsbP1Y7BAR1/A7MzSEIXQvQZHT1yZGiQK0ODekcyBxnlIoQQfYYkdCGE6CMkoQshRB8hCV0IIfoISehCCNFHSEIXQog+QhK6EEL0EZLQhRCij1Bat7qaXOe/sVI5QMopHu4FdN6yHx2nN8QpMXYMibFjSIwnFqq1bnWax25L6H+EUiq2Nyyg0RvilBg7hsTYMSTGP0ZKLkII0UdIQhdCiD6ityb0t7o7gHbqDXFKjB1DYuwYEuMf0Ctr6EIIIVrqrT10IYQQx5CELoQQfUSvS+hKqVlKqX1KqSSl1EPdHQ+AUipYKbVGKbVXKbVHKfVny3YPpdRKpVSi5b+dszLsycVqVkptV0p91xNjVEq5KaWWKqUSLD/PCT0wxnss/85xSqlPlFJ2PSFGpdS7SqlspVRck21txqWUetjye7RPKTWzG2N8wfLvvUsp9ZVSyq2nxdhk331KKa2U8mqyrctjbEuvSuhKKTPwGjAbGARcrpQa1L1RAVAL3Ku1HgiMB+6wxPUQsEprHQWssrzubn8G9jZ53dNifBn4SWs9ABiOEWuPiVEpFQjcDcRorYcAZmBBD4nxfWDWMdtajcvy/+cCYLDlmNctv1/dEeNKYIjWehiwH3i4B8aIUioYOBs43GRbd8XYql6V0IGxQJLWOllrXQ0sAeZ2c0xorY9orbdZvi/BSEKBGLF9YGn2ATCvWwK0UEoFAXOAt5ts7jExKqVcgKnAOwBa62qtdSE9KEYLK8BeKWUFOAAZ9IAYtdZrgfxjNrcV11xgida6Smt9EEjC+P3q8hi11iu01rWWlxuBoJ4Wo8VLwANA05Ek3RJjW3pbQg8EUpu8TrNs6zGUUmHASGAT4Ku1PgJG0gd8ujE0gP9g/A9Z32RbT4oxAsgB3rOUhd5WSjn2pBi11unAvzB6aUeAIq31ip4U4zHaiqun/i7dAPxo+b7HxKiUugBI11rvPGZXj4kRel9CV61s6zHjLpVSTsAXwF+01sXdHU9TSqnzgGyt9dbujuU4rIBRwBta65FAGd1fAmrGUoOeC4QDAYCjUuqq7o3qlPS43yWl1CMY5cvFDZtaadblMSqlHIBHgMdb293Ktm77Ofa2hJ4GBDd5HYTx5263U0pZYyTzxVrrLy2bs5RS/pb9/kB2d8UHTAIuUEodwihVTVdKfUTPijENSNNab7K8XoqR4HtSjDOAg1rrHK11DfAlMLGHxdhUW3H1qN8lpdS1wHnAlfrowzE9JcZIjA/wnZbfnyBgm1LKj54TI9D7EvoWIEopFa6UssG4GbGsm2NCKaUw6r57tdYvNtm1DLjW8v21wDddHVsDrfXDWusgrXUYxs9ttdb6KnpWjJlAqlIq2rLpLCCeHhQjRqllvFLKwfLvfhbGPZOeFGNTbcW1DFiglLJVSoUDUcDmbogPpdQs4EHgAq11eZNdPSJGrfVurbWP1jrM8vuTBoyy/P/aI2JsGmyv+gLOxbgTfgB4pLvjscQ0GePPrF3ADsvXuYAnxsiCRMt/Pbo7Vku8ZwLfWb7vUTECI4BYy8/ya8C9B8b4FJAAxAGLANueECPwCUZdvwYj6dx4vLgwyggHgH3A7G6MMQmjDt3wu7Owp8V4zP5DgFd3xtjWlzz6L4QQfURvK7kIIYRogyR0IYToIyShCyFEHyEJXQgh+ghJ6EII0UdIQhdCiD5CEroQQvQR/w+kpvx7nHWh7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kayipDF=pd.DataFrame(model.history.history)\n",
    "kayipDF.plot()\n",
    "#modelimiz artık daha iyi bir hal aldı görüldüğü gibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computer\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tahminlerimiz = model.predict_classes(x_test)\n",
    "# sınıfları tahmin et dedik\n",
    "tahminlerimiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# bu iki sınıf doğruluk oranını ölçmek için kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91        91\n",
      "           1       0.93      0.84      0.88        74\n",
      "\n",
      "    accuracy                           0.90       165\n",
      "   macro avg       0.90      0.89      0.89       165\n",
      "weighted avg       0.90      0.90      0.90       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tahminlerimiz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  5]\n",
      " [12 62]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, tahminlerimiz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
